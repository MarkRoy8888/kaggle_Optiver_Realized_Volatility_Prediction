{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a3092d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-27T09:36:04.368641Z",
     "iopub.status.busy": "2021-09-27T09:36:04.367811Z",
     "iopub.status.idle": "2021-09-27T09:36:05.720164Z",
     "shell.execute_reply": "2021-09-27T09:36:05.719347Z",
     "shell.execute_reply.started": "2021-09-26T02:13:31.084486Z"
    },
    "papermill": {
     "duration": 1.392564,
     "end_time": "2021-09-27T09:36:05.720370",
     "exception": false,
     "start_time": "2021-09-27T09:36:04.327806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "\n",
    "# path_submissions = '/'\n",
    "# target_name = 'target'\n",
    "# scores_folds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf07a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T09:36:05.792392Z",
     "iopub.status.busy": "2021-09-27T09:36:05.790945Z",
     "iopub.status.idle": "2021-09-27T09:36:05.857446Z",
     "shell.execute_reply": "2021-09-27T09:36:05.856816Z",
     "shell.execute_reply.started": "2021-09-26T02:13:32.325666Z"
    },
    "papermill": {
     "duration": 0.106067,
     "end_time": "2021-09-27T09:36:05.857588",
     "exception": false,
     "start_time": "2021-09-27T09:36:05.751521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data directory\n",
    "data_dir = '../input/optiver-realized-volatility-prediction/'\n",
    "\n",
    "\n",
    "# My function \n",
    "def BidAskSpread(df):\n",
    "    return ((df['ask_price1']/df['bid_price1'])-1)\n",
    "def Wap1(df):\n",
    "    return (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "def Wap2(df):\n",
    "    return (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "def Wap3(df):\n",
    "    return (df['bid_price1'] * df['bid_size1'] + df['ask_price1'] * df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "def Wap4(df):\n",
    "    return (df['bid_price2'] * df['bid_size2'] + df['ask_price2'] * df['ask_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "def BidAsk_price_gap(df):\n",
    "    return (df['ask_price1']-df['bid_price1'])\n",
    "def BidAsk_price_center(df):\n",
    "    return ((df['ask_price1']+df['bid_price1'])/2)\n",
    "\n",
    "def BidAsk_size_gap(df):\n",
    "    return (abs(df['ask_size1']-df['bid_size1']))\n",
    "def BidAsk_size_center(df):\n",
    "    return ((df['ask_size1']+df['bid_size1'])/2)\n",
    " \n",
    "def BidAsk_Weighted_center(df):\n",
    "    gap= df['ask_price1']-df['bid_price1']\n",
    "    center= ((df['ask_price1']+df['bid_price1'])/2)\n",
    "    add_weight=abs((df['ask_price1']-center)*df['ask_size1'])\n",
    "    mins_weight=abs((df['bid_price1']-center)*df['bid_size1'])\n",
    "    weight_center=center+gap*(add_weight-mins_weight)/(add_weight+mins_weight)\n",
    "    return (weight_center)\n",
    "def Bid_spread(df):\n",
    "    return (df['bid_price1'] - df['bid_price2'])\n",
    "def Ask_spread(df):\n",
    "    return (abs(df['ask_price1'] - df['ask_price2']))\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "# Add feature\n",
    "def BidAsk_size12_gap(df):\n",
    "    return (abs(df['ask_size1']+df['ask_size2']-df['bid_size1']-df['bid_size2']))\n",
    "def Wap12(df):\n",
    "    return (df['bid_price1'] * df['ask_size1'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size1'] + df['ask_size2'])\n",
    "def Wap21(df):\n",
    "    return (df['bid_price2'] * df['ask_size2'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size2'] + df['ask_size1'])\n",
    "def BidAskSpread12(df):\n",
    "    return ((df['ask_price1']/df['bid_price2'])-1)\n",
    "def BidAskSpread21(df):\n",
    "    return ((df['ask_price2']/df['bid_price2'])-1)\n",
    "def BidAsk_size_add_gap(df):\n",
    "    return (abs(df['ask_size1']+df['ask_size2']-df['bid_size1']-df['bid_size2']))\n",
    "\n",
    "\n",
    "def bid_size_weight(df):\n",
    "    return np.sqrt((np.square(df['bid_size1'])+np.square(df['bid_size2']))/(np.square(df['bid_size1'])+np.square(df['bid_size2'])+np.square(df['ask_size1'])+np.square(df['ask_size2'])))\n",
    "\n",
    "def ask_size_weight(df):\n",
    "    return np.sqrt((np.square(df['ask_size1'])+np.square(df['ask_size2']))/(np.square(df['bid_size1'])+np.square(df['bid_size2'])+np.square(df['ask_size1'])+np.square(df['ask_size2'])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def total_diff_size(df):\n",
    "    return  (abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2'])))\n",
    "def total_size(df):\n",
    "    return  (abs((df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])))\n",
    "def price_spread(df):\n",
    "    return (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "def price_spread2(df):\n",
    "    return (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2) \n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate the log of the return\n",
    "# Remember that logb(x / y) = logb(x) - logb(y)\n",
    "def log_return(series):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "# Calculate the realized volatility\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "# Function to count unique elements of a series\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "\n",
    "\n",
    "# Function to read our base train and test set\n",
    "def read_train_test():\n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n",
    "    # Create a key to merge with book and trade data\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    #print(f'Our training set has {train.shape[0]} rows')\n",
    "    return train,test\n",
    "\n",
    "# Function to preprocess book data (for each stock id)\n",
    "def book_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    # Calculate Wap\n",
    "    df['wap1'] = Wap1(df)\n",
    "    df['wap2'] = Wap2(df)\n",
    "    df['wap3'] = Wap3(df)\n",
    "    df['wap4'] = Wap4(df)\n",
    "    \n",
    "    df['BidAsk_price_gap'] = BidAsk_price_gap(df)\n",
    "    df['BidAsk_price_center'] = BidAsk_price_center(df)\n",
    "    df['BidAsk_size_gap'] = BidAsk_size_gap(df)\n",
    "    df['BidAsk_size_center'] = BidAsk_size_center(df)\n",
    "    df['BidAsk_Weighted_center'] = BidAsk_Weighted_center(df)\n",
    "    df['Bid_spread'] = Bid_spread(df)\n",
    "    df['Ask_spread'] = Ask_spread(df)\n",
    "#     df['Wap12'] = Wap12(df)\n",
    "#     df['Wap21'] = Wap21(df)\n",
    "    \n",
    "    df['BidAsk_size12_gap'] = BidAsk_size12_gap(df)   \n",
    "    df['Wap12'] = Wap12(df)    \n",
    "    df['Wap21'] = Wap21(df)    \n",
    "    df['BidAskSpread12'] = BidAskSpread12(df)    \n",
    "    df['BidAskSpread21'] = BidAskSpread21(df)    \n",
    "\n",
    "    df['BidAskSpread'] = BidAskSpread(df)\n",
    "    df['BidAsk_size_add_gap'] = BidAsk_size_add_gap(df) \n",
    "    df['bid_size_weight'] = bid_size_weight(df) \n",
    "    df['ask_size_weight'] = ask_size_weight(df) \n",
    "    #\n",
    "    df['total_diff_size'] = total_diff_size(df) \n",
    "    df['total_size'] = total_size(df) \n",
    "    df['price_spread'] = price_spread(df) \n",
    "    df['price_spread2'] = price_spread2(df) \n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    df['log_return3'] = df.groupby(['time_id'])['wap3'].apply(log_return)\n",
    "    df['log_return4'] = df.groupby(['time_id'])['wap4'].apply(log_return)\n",
    "    df['log_return12'] = df.groupby(['time_id'])['Wap12'].apply(log_return)\n",
    "    df['log_return21'] = df.groupby(['time_id'])['Wap21'].apply(log_return)\n",
    "    \n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'wap1': [np.sum, np.std],\n",
    "        'wap2': [np.sum, np.std],\n",
    "        'wap3': [np.sum, np.std],\n",
    "        'wap4': [np.sum, np.std],\n",
    "        'Wap12': [np.sum, np.std],\n",
    "        'Wap21': [np.sum, np.std],\n",
    "        \n",
    "        \n",
    "        'BidAsk_price_gap': [np.mean, np.std],\n",
    "        'BidAsk_size_gap': [np.mean, np.std],\n",
    "        'BidAsk_size_center': [np.mean, np.std],\n",
    "        'BidAsk_Weighted_center': [np.mean, np.std],\n",
    "        'BidAsk_price_center': [np.mean, np.std],\n",
    "\n",
    "        \n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "        \n",
    "        'BidAsk_size12_gap': [np.sum, np.std],\n",
    "        'BidAskSpread12': [np.sum, np.max],\n",
    "        'BidAskSpread21': [np.sum, np.max],\n",
    "        \n",
    "        \n",
    "        'BidAsk_size_add_gap': [np.sum, np.max],\n",
    "#         'BidAskSpread21': [np.sum, np.max,np.min],\n",
    "        'bid_size_weight': [np.sum, np.max],\n",
    "        'ask_size_weight': [np.sum, np.max],\n",
    "        \n",
    "\n",
    "        'wap_balance': [np.sum, np.max],\n",
    "        'price_spread':[np.sum, np.max],\n",
    "        'price_spread2':[np.sum, np.max],\n",
    "        'Bid_spread':[np.sum, np.max],\n",
    "        'Ask_spread':[np.sum, np.max],\n",
    "        'total_size':[np.sum, np.max],\n",
    "        'total_diff_size':[np.sum, np.max],\n",
    "        \"BidAskSpread\":[np.sum, np.max],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "        'log_return12': [realized_volatility],\n",
    "        'log_return21': [realized_volatility],\n",
    "    }\n",
    "    \n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    def get_stats_window_re(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] <= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "#     df_feature_450 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 450, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "#     df_feature_350 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 350, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "#     df_feature_250 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 250, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "#     df_feature_150 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 150, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "#     df_feature_50 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 50, add_suffix = True)\n",
    "    # Get the stats for different windows\n",
    "#     df_feature = get_stats_window_re(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500_re = get_stats_window_re(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "#     df_feature_450_re = get_stats_window_re(create_feature_dict_time,seconds_in_bucket = 450, add_suffix = True)\n",
    "    df_feature_400_re = get_stats_window_re(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "#     df_feature_350_re = get_stats_window_re(create_feature_dict_time,seconds_in_bucket = 350, add_suffix = True)\n",
    "    df_feature_300_re = get_stats_window_re(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "#     df_feature_250_re = get_stats_window_re(create_feature_dict_time,seconds_in_bucket = 250, add_suffix = True)\n",
    "    df_feature_200_re = get_stats_window_re(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "#     df_feature_150_re = get_stats_window_re(create_feature_dict_time,seconds_in_bucket = 150, add_suffix = True)\n",
    "    df_feature_100_re = get_stats_window_re(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "#     df_feature_50_re = get_stats_window_re(create_feature_dict_time,seconds_in_bucket = 50, add_suffix = True)\n",
    "    \n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "#     df_feature = df_feature.merge(df_feature_450, how = 'left', left_on = 'time_id_', right_on = 'time_id__450')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "#     df_feature = df_feature.merge(df_feature_350, how = 'left', left_on = 'time_id_', right_on = 'time_id__350')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "#     df_feature = df_feature.merge(df_feature_250, how = 'left', left_on = 'time_id_', right_on = 'time_id__250')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "#     df_feature = df_feature.merge(df_feature_150, how = 'left', left_on = 'time_id_', right_on = 'time_id__150')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "#     df_feature = df_feature.merge(df_feature_50, how = 'left', left_on = 'time_id_', right_on = 'time_id__50')\n",
    "    # Drop unnecesary time_ids\n",
    "#     df_feature.drop(['time_id__500','time_id__450','time_id__400','time_id__350', 'time_id__300','time_id__250', 'time_id__200','time_id__150','time_id__100','time_id__50'], axis = 1, inplace = True)\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'], axis = 1, inplace = True)\n",
    "    ##############################################################################################################\n",
    "\n",
    "#     df_feature.drop(['time_id__500','time_id__450','time_id__400','time_id__350', 'time_id__300','time_id__250', 'time_id__200','time_id__150','time_id__100','time_id__50'], axis = 1, inplace = True)\n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500_re, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "#     df_feature = df_feature.merge(df_feature_450_re, how = 'left', left_on = 'time_id_', right_on = 'time_id__450')\n",
    "    df_feature = df_feature.merge(df_feature_400_re, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "#     df_feature = df_feature.merge(df_feature_350_re, how = 'left', left_on = 'time_id_', right_on = 'time_id__350')\n",
    "    df_feature = df_feature.merge(df_feature_300_re, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "#     df_feature = df_feature.merge(df_feature_250_re, how = 'left', left_on = 'time_id_', right_on = 'time_id__250')\n",
    "    df_feature = df_feature.merge(df_feature_200_re, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "#     df_feature = df_feature.merge(df_feature_150_re, how = 'left', left_on = 'time_id_', right_on = 'time_id__150')\n",
    "    df_feature = df_feature.merge(df_feature_100_re, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "#     df_feature = df_feature.merge(df_feature_50_re, how = 'left', left_on = 'time_id_', right_on = 'time_id__50')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to preprocess trade data (for each stock id)\n",
    "def trade_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    df['amount']=df['price']*df['size']\n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, np.max, np.min],\n",
    "        'order_count':[np.sum,np.max,np.min],\n",
    "        'amount':[np.sum,np.max,np.min],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.sum],\n",
    "    }\n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "\n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "#     df_feature_450 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 450, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "#     df_feature_350 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 350, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "#     df_feature_250 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 250, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "#     df_feature_150 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 150, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "#     df_feature_50 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 50, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        # new\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        \n",
    "        # vol vars\n",
    "        \n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "#     df_feature = df_feature.merge(df_feature_450, how = 'left', left_on = 'time_id_', right_on = 'time_id__450')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "#     df_feature = df_feature.merge(df_feature_350, how = 'left', left_on = 'time_id_', right_on = 'time_id__350')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "#     df_feature = df_feature.merge(df_feature_250, how = 'left', left_on = 'time_id_', right_on = 'time_id__250')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "#     df_feature = df_feature.merge(df_feature_150, how = 'left', left_on = 'time_id_', right_on = 'time_id__150')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "#     df_feature = df_feature.merge(df_feature_50, how = 'left', left_on = 'time_id_', right_on = 'time_id__50')\n",
    "    # Drop unnecesary time_ids\n",
    "#     df_feature.drop(['time_id__500','time_id__450','time_id__400','time_id__350', 'time_id__300','time_id__250', 'time_id__200','time_id','time_id__150','time_id__100','time_id__50'], axis = 1, inplace = True)\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to get group stats for the stock_id and time_id\n",
    "def get_time_stock(df):\n",
    "#     vol_cols = ['log_return1_realized_volatility','log_return2_realized_volatility',\n",
    "# #                 'log_return2_realized_volatility_450_x',\n",
    "#                    'log_return1_realized_volatility_400_x', 'log_return2_realized_volatility_400_x',\n",
    "# #        'log_return1_realized_volatility_350_x',\n",
    "#                 'log_return1_realized_volatility_300_x',\n",
    "# #        'log_return2_realized_volatility_350_x',\n",
    "#                 'log_return2_realized_volatility_300_x',\n",
    "#                 'log_return1_realized_volatility_200_x', \n",
    "# #                 'trade_log_return_realized_volatility_250',\n",
    "#        'log_return2_realized_volatility_200_x', 'trade_log_return_realized_volatility',\n",
    "#        'trade_log_return_realized_volatility_450', 'trade_log_return_realized_volatility_400',\n",
    "# #        'trade_log_return_realized_volatility_350', \n",
    "#                 'trade_log_return_realized_volatility_300',\n",
    "# #      'trade_log_return_realized_volatility_250',\n",
    "# #        'log_return1_realized_volatility_450_x',\n",
    "#                 'trade_log_return_realized_volatility_200']\n",
    "#         vol_cols = ['log_return1_realized_volatility',\n",
    "#                     'log_return2_realized_volatility',\n",
    "#                     'log_return1_realized_volatility_400_x',\n",
    "#                     'log_return2_realized_volatility_400_x',\n",
    "#                     'log_return1_realized_volatility_300_x',\n",
    "#                     'log_return2_realized_volatility_300_x',\n",
    "#                     'log_return1_realized_volatility_200_x', \n",
    "#                     'log_return2_realized_volatility_200_x',\n",
    "#                     'trade_log_return_realized_volatility',\n",
    "#                     'trade_log_return_realized_volatility_450',\n",
    "#                     'trade_log_return_realized_volatility_400',\n",
    "#                     'trade_log_return_realized_volatility_300',\n",
    "#                     'trade_log_return_realized_volatility_200']\n",
    "    vol_cols = ['log_return1_realized_volatility',\n",
    "                'log_return2_realized_volatility',\n",
    "                'log_return1_realized_volatility_400_x',\n",
    "                'log_return2_realized_volatility_400_x',\n",
    "                'log_return1_realized_volatility_300_x',\n",
    "                'log_return2_realized_volatility_300_x',\n",
    "                'log_return1_realized_volatility_200_x', \n",
    "                'log_return2_realized_volatility_200_x',\n",
    "                    \n",
    "                'log_return1_realized_volatility_400_y',\n",
    "                'log_return2_realized_volatility_400_y',\n",
    "                'log_return1_realized_volatility_300_y',\n",
    "                'log_return2_realized_volatility_300_y',\n",
    "                'log_return1_realized_volatility_200_y', \n",
    "                'log_return2_realized_volatility_200_y',\n",
    "                'trade_log_return_realized_volatility',\n",
    "#                 'trade_log_return_realized_volatility_450',\n",
    "                'trade_log_return_realized_volatility_400',\n",
    "                'trade_log_return_realized_volatility_300',\n",
    "                'trade_log_return_realized_volatility_200']\n",
    "\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max']).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max']).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    return df\n",
    "    \n",
    "# Funtion to make preprocessing function in parallel (for each stock id)\n",
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    \n",
    "    # Parrallel for loop\n",
    "    def for_joblib(stock_id):\n",
    "        # Train\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        # Test\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "    \n",
    "        # Preprocess book and trade data and merge them\n",
    "        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n",
    "        \n",
    "        # Return the merge dataframe\n",
    "        return df_tmp\n",
    "    \n",
    "    # Use parallel api to call paralle for loop\n",
    "    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n",
    "    # Concatenate all the dataframes that return from Parallel\n",
    "    df = pd.concat(df, ignore_index = True)\n",
    "    return df\n",
    "\n",
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a8114c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T09:36:05.919016Z",
     "iopub.status.busy": "2021-09-27T09:36:05.918388Z",
     "iopub.status.idle": "2021-09-27T09:36:05.920523Z",
     "shell.execute_reply": "2021-09-27T09:36:05.920935Z",
     "shell.execute_reply.started": "2021-09-26T02:13:32.424592Z"
    },
    "papermill": {
     "duration": 0.034585,
     "end_time": "2021-09-27T09:36:05.921123",
     "exception": false,
     "start_time": "2021-09-27T09:36:05.886538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vol_cols = ['log_return1_realized_volatility','log_return2_realized_volatility','log_return2_realized_volatility_450',\n",
    "#        'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400',\n",
    "#        'log_return1_realized_volatility_350','log_return1_realized_volatility_300',\n",
    "#        'log_return2_realized_volatility_350', 'log_return2_realized_volatility_300',\n",
    "#        'log_return1_realized_volatility_200', 'trade_log_return_realized_volatility_250',\n",
    "#        'log_return2_realized_volatility_200', 'trade_log_return_realized_volatility',\n",
    "#        'trade_log_return_realized_volatility_450', 'trade_log_return_realized_volatility_400',\n",
    "#        'trade_log_return_realized_volatility_350', 'trade_log_return_realized_volatility_300',\n",
    "# #      'trade_log_return_realized_volatility_250',\n",
    "#        'log_return1_realized_volatility_450','trade_log_return_realized_volatility_200']\n",
    "# train['trade_log_return_realized_volatility_250']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f00ee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T09:36:05.979488Z",
     "iopub.status.busy": "2021-09-27T09:36:05.978830Z",
     "iopub.status.idle": "2021-09-27T09:36:06.878756Z",
     "shell.execute_reply": "2021-09-27T09:36:06.878215Z",
     "shell.execute_reply.started": "2021-09-26T02:13:32.444817Z"
    },
    "papermill": {
     "duration": 0.930307,
     "end_time": "2021-09-27T09:36:06.878900",
     "exception": false,
     "start_time": "2021-09-27T09:36:05.948593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read train and test\n",
    "# train =pd.read_pickle(\"../input/optiver006/train.pkl\")\n",
    "train,test = read_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee15c35e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T09:36:06.941505Z",
     "iopub.status.busy": "2021-09-27T09:36:06.940868Z",
     "iopub.status.idle": "2021-09-27T09:36:06.942770Z",
     "shell.execute_reply": "2021-09-27T09:36:06.943177Z",
     "shell.execute_reply.started": "2021-09-26T02:13:34.01024Z"
    },
    "papermill": {
     "duration": 0.034205,
     "end_time": "2021-09-27T09:36:06.943349",
     "exception": false,
     "start_time": "2021-09-27T09:36:06.909144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "850e3ddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T09:36:07.004121Z",
     "iopub.status.busy": "2021-09-27T09:36:07.003373Z",
     "iopub.status.idle": "2021-09-27T10:59:23.156947Z",
     "shell.execute_reply": "2021-09-27T10:59:23.156379Z",
     "shell.execute_reply.started": "2021-09-26T02:13:34.016031Z"
    },
    "papermill": {
     "duration": 4996.184384,
     "end_time": "2021-09-27T10:59:23.157140",
     "exception": false,
     "start_time": "2021-09-27T09:36:06.972756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed: 83.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Get unique stock ids \n",
    "train_stock_ids = train['stock_id'].unique()\n",
    "train_ = preprocessor(train_stock_ids, is_train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8933af6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:23.220510Z",
     "iopub.status.busy": "2021-09-27T10:59:23.219840Z",
     "iopub.status.idle": "2021-09-27T10:59:23.711253Z",
     "shell.execute_reply": "2021-09-27T10:59:23.710719Z",
     "shell.execute_reply.started": "2021-09-26T03:34:26.585732Z"
    },
    "papermill": {
     "duration": 0.525535,
     "end_time": "2021-09-27T10:59:23.711406",
     "exception": false,
     "start_time": "2021-09-27T10:59:23.185871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2df9fff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:23.777825Z",
     "iopub.status.busy": "2021-09-27T10:59:23.775495Z",
     "iopub.status.idle": "2021-09-27T10:59:28.292908Z",
     "shell.execute_reply": "2021-09-27T10:59:28.292244Z",
     "shell.execute_reply.started": "2021-09-26T03:34:27.099854Z"
    },
    "papermill": {
     "duration": 4.552668,
     "end_time": "2021-09-27T10:59:28.293103",
     "exception": false,
     "start_time": "2021-09-27T10:59:23.740435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Preprocess them using Parallel and our single stock id functions\n",
    "train = train.merge(train_, on = ['row_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a00246f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:28.366245Z",
     "iopub.status.busy": "2021-09-27T10:59:28.365133Z",
     "iopub.status.idle": "2021-09-27T10:59:28.380034Z",
     "shell.execute_reply": "2021-09-27T10:59:28.379368Z",
     "shell.execute_reply.started": "2021-09-26T03:34:31.285651Z"
    },
    "papermill": {
     "duration": 0.055719,
     "end_time": "2021-09-27T10:59:28.380231",
     "exception": false,
     "start_time": "2021-09-27T10:59:28.324512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd1c7f",
   "metadata": {
    "papermill": {
     "duration": 0.031719,
     "end_time": "2021-09-27T10:59:28.443439",
     "exception": false,
     "start_time": "2021-09-27T10:59:28.411720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd28ccc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:28.511690Z",
     "iopub.status.busy": "2021-09-27T10:59:28.510995Z",
     "iopub.status.idle": "2021-09-27T10:59:28.514703Z",
     "shell.execute_reply": "2021-09-27T10:59:28.513996Z",
     "shell.execute_reply.started": "2021-09-26T03:34:31.303492Z"
    },
    "papermill": {
     "duration": 0.039624,
     "end_time": "2021-09-27T10:59:28.514874",
     "exception": false,
     "start_time": "2021-09-27T10:59:28.475250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range((test.shape[1])):\n",
    "#     print(test.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "409a914c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:28.583605Z",
     "iopub.status.busy": "2021-09-27T10:59:28.582553Z",
     "iopub.status.idle": "2021-09-27T10:59:28.585994Z",
     "shell.execute_reply": "2021-09-27T10:59:28.585405Z",
     "shell.execute_reply.started": "2021-09-26T03:34:31.308849Z"
    },
    "papermill": {
     "duration": 0.039395,
     "end_time": "2021-09-27T10:59:28.586170",
     "exception": false,
     "start_time": "2021-09-27T10:59:28.546775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train.columns\n",
    "# train[['log_return1_realized_volatility','log_return2_realized_volatility','log_return2_realized_volatility_450',\n",
    "#        'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400',\n",
    "#        'log_return1_realized_volatility_350','log_return1_realized_volatility_300',\n",
    "#        'log_return2_realized_volatility_350', 'log_return2_realized_volatility_300',\n",
    "#        'log_return1_realized_volatility_200', 'trade_log_return_realized_volatility_250',\n",
    "#        'log_return2_realized_volatility_200', 'trade_log_return_realized_volatility',\n",
    "#        'trade_log_return_realized_volatility_450', 'trade_log_return_realized_volatility_400',\n",
    "#        'trade_log_return_realized_volatility_350', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_250',\n",
    "#        'log_return1_realized_volatility_450','trade_log_return_realized_volatility_200']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f546bc7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:28.663094Z",
     "iopub.status.busy": "2021-09-27T10:59:28.661242Z",
     "iopub.status.idle": "2021-09-27T10:59:34.900825Z",
     "shell.execute_reply": "2021-09-27T10:59:34.900127Z",
     "shell.execute_reply.started": "2021-09-26T03:34:31.321965Z"
    },
    "papermill": {
     "duration": 6.282096,
     "end_time": "2021-09-27T10:59:34.900993",
     "exception": false,
     "start_time": "2021-09-27T10:59:28.618897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get group stats of time_id and stock_id\n",
    "train = get_time_stock(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f6fdf49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:34.968488Z",
     "iopub.status.busy": "2021-09-27T10:59:34.966159Z",
     "iopub.status.idle": "2021-09-27T10:59:35.064807Z",
     "shell.execute_reply": "2021-09-27T10:59:35.064151Z",
     "shell.execute_reply.started": "2021-09-26T03:34:37.393931Z"
    },
    "papermill": {
     "duration": 0.132684,
     "end_time": "2021-09-27T10:59:35.064946",
     "exception": false,
     "start_time": "2021-09-27T10:59:34.932262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = get_time_stock(test)\n",
    "# train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6320fcc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:35.137623Z",
     "iopub.status.busy": "2021-09-27T10:59:35.136601Z",
     "iopub.status.idle": "2021-09-27T10:59:35.162709Z",
     "shell.execute_reply": "2021-09-27T10:59:35.162069Z",
     "shell.execute_reply.started": "2021-09-26T03:34:37.503954Z"
    },
    "papermill": {
     "duration": 0.068579,
     "end_time": "2021-09-27T10:59:35.162843",
     "exception": false,
     "start_time": "2021-09-27T10:59:35.094264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace by order sum (tau)\n",
    "#train['size_tau_500'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_500'] )\n",
    "#test['size_tau_500'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_500'])\n",
    "train['size_tau'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique'] )\n",
    "test['size_tau'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique'] )\n",
    "# train['size_tau_450'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_450'] )\n",
    "# test['size_tau_450'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_450'] )\n",
    "train['size_tau_400'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_400'] )\n",
    "test['size_tau_400'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_400'] )\n",
    "train['size_tau_300'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_300'] )\n",
    "test['size_tau_300'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_300'] )\n",
    "# train['size_tau_150'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_150'] )\n",
    "# test['size_tau_150'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_150'] )\n",
    "train['size_tau_200'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_200'] )\n",
    "test['size_tau_200'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_200'] )\n",
    "\n",
    "train['size_tau_100'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_100'] )\n",
    "test['size_tau_100'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_100'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90bb1ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:35.232117Z",
     "iopub.status.busy": "2021-09-27T10:59:35.231241Z",
     "iopub.status.idle": "2021-09-27T10:59:35.265686Z",
     "shell.execute_reply": "2021-09-27T10:59:35.264458Z",
     "shell.execute_reply.started": "2021-09-26T03:34:37.535835Z"
    },
    "papermill": {
     "duration": 0.073256,
     "end_time": "2021-09-27T10:59:35.265839",
     "exception": false,
     "start_time": "2021-09-27T10:59:35.192583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['size_tau2'] = np.sqrt( 1/ train['trade_order_count_sum'] )\n",
    "test['size_tau2'] = np.sqrt( 1/ test['trade_order_count_sum'] )\n",
    "\n",
    "#train['size_tau2_500'] = np.sqrt( 0.15/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_500'] = np.sqrt( 0.15/ test['trade_order_count_sum'] )\n",
    "\n",
    "train['size_tau2_400'] = np.sqrt( 0.33/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_400'] = np.sqrt( 0.33/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_300'] = np.sqrt( 0.5/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_300'] = np.sqrt( 0.5/ test['trade_order_count_sum'] )\n",
    "# train['size_tau2_150'] = np.sqrt( 0.75/ train['trade_order_count_sum'] )\n",
    "# test['size_tau2_150'] = np.sqrt( 0.75/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_200'] = np.sqrt( 0.66/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_200'] = np.sqrt( 0.66/ test['trade_order_count_sum'] )\n",
    "\n",
    "train['size_tau2_100'] = np.sqrt( 0.88/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_100'] = np.sqrt( 0.88/ test['trade_order_count_sum'] )\n",
    "\n",
    "\n",
    "# delta tau\n",
    "train['size_tau2_d'] = train['size_tau2_400'] - train['size_tau2']\n",
    "test['size_tau2_d'] = test['size_tau2_400'] - test['size_tau2']\n",
    "\n",
    "train['size_tau2_d1'] = train['size_tau2_300'] - train['size_tau2_400']\n",
    "test['size_tau2_d1'] = test['size_tau2_300'] - test['size_tau2_400']\n",
    "train['size_tau2_d2'] = train['size_tau2_200'] - train['size_tau2_300']\n",
    "test['size_tau2_d2'] = test['size_tau2_200'] - test['size_tau2_300']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4433f260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:35.331966Z",
     "iopub.status.busy": "2021-09-27T10:59:35.331016Z",
     "iopub.status.idle": "2021-09-27T10:59:35.334788Z",
     "shell.execute_reply": "2021-09-27T10:59:35.334277Z",
     "shell.execute_reply.started": "2021-09-26T03:34:37.57415Z"
    },
    "papermill": {
     "duration": 0.040008,
     "end_time": "2021-09-27T10:59:35.334932",
     "exception": false,
     "start_time": "2021-09-27T10:59:35.294924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_.shape,test_.shape\n",
    "# colNames = [col for col in list(train.columns)\n",
    "#             if col not in {\"stock_id\", \"time_id\", \"target\", \"row_id\"}]\n",
    "# len(colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "895e4613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:35.404285Z",
     "iopub.status.busy": "2021-09-27T10:59:35.403080Z",
     "iopub.status.idle": "2021-09-27T10:59:35.701936Z",
     "shell.execute_reply": "2021-09-27T10:59:35.701249Z",
     "shell.execute_reply.started": "2021-09-26T03:34:37.579311Z"
    },
    "papermill": {
     "duration": 0.33719,
     "end_time": "2021-09-27T10:59:35.702107",
     "exception": false,
     "start_time": "2021-09-27T10:59:35.364917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=train.reset_index()\n",
    "test=test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a1d13d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:35.780597Z",
     "iopub.status.busy": "2021-09-27T10:59:35.779710Z",
     "iopub.status.idle": "2021-09-27T10:59:39.075146Z",
     "shell.execute_reply": "2021-09-27T10:59:39.074104Z",
     "shell.execute_reply.started": "2021-09-26T03:34:37.855944Z"
    },
    "papermill": {
     "duration": 3.339039,
     "end_time": "2021-09-27T10:59:39.075311",
     "exception": false,
     "start_time": "2021-09-27T10:59:35.736272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "[81]\n",
      "[8, 80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:43: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:47: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# making agg features\n",
    "\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()\n",
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cde7eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:39.141916Z",
     "iopub.status.busy": "2021-09-27T10:59:39.141302Z",
     "iopub.status.idle": "2021-09-27T10:59:39.144579Z",
     "shell.execute_reply": "2021-09-27T10:59:39.144994Z",
     "shell.execute_reply.started": "2021-09-26T03:34:40.919735Z"
    },
    "papermill": {
     "duration": 0.038067,
     "end_time": "2021-09-27T10:59:39.145193",
     "exception": false,
     "start_time": "2021-09-27T10:59:39.107126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train\n",
    "# len(mat1)\n",
    "# for col in mat1.columns:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b78a6364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:39.246008Z",
     "iopub.status.busy": "2021-09-27T10:59:39.244991Z",
     "iopub.status.idle": "2021-09-27T10:59:58.407974Z",
     "shell.execute_reply": "2021-09-27T10:59:58.408479Z",
     "shell.execute_reply.started": "2021-09-26T03:34:40.924386Z"
    },
    "papermill": {
     "duration": 19.221583,
     "end_time": "2021-09-27T10:59:58.408674",
     "exception": false,
     "start_time": "2021-09-27T10:59:39.187091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_diff_size_sum_0c1',\n",
    "     'total_diff_size_sum_1c1', \n",
    "     'total_diff_size_sum_3c1',\n",
    "     'total_diff_size_sum_4c1', \n",
    "     'total_diff_size_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'Bid_spread_sum_0c1',\n",
    "     'Bid_spread_sum_1c1',\n",
    "     'Bid_spread_sum_3c1',\n",
    "     'Bid_spread_sum_4c1',\n",
    "     'Bid_spread_sum_6c1',       \n",
    "     'Ask_spread_sum_0c1',\n",
    "     'Ask_spread_sum_1c1',\n",
    "     'Ask_spread_sum_3c1',\n",
    "     'Ask_spread_sum_4c1',\n",
    "     'Ask_spread_sum_6c1',   \n",
    "     'total_size_sum_0c1',\n",
    "     'total_size_sum_1c1',\n",
    "     'total_size_sum_3c1',\n",
    "     'total_size_sum_4c1',\n",
    "     'total_size_sum_6c1',       \n",
    "     'BidAskSpread_sum_0c1',\n",
    "     'BidAskSpread_sum_1c1',\n",
    "     'BidAskSpread_sum_3c1',\n",
    "     'BidAskSpread_sum_4c1',\n",
    "     'BidAskSpread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] \n",
    "train = pd.merge(train,mat1[nnn],how='left',on='time_id')\n",
    "test = pd.merge(test,mat2[nnn],how='left',on='time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "664efdcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:58.606670Z",
     "iopub.status.busy": "2021-09-27T10:59:58.605945Z",
     "iopub.status.idle": "2021-09-27T10:59:58.610169Z",
     "shell.execute_reply": "2021-09-27T10:59:58.609702Z",
     "shell.execute_reply.started": "2021-09-26T03:34:58.155312Z"
    },
    "papermill": {
     "duration": 0.16938,
     "end_time": "2021-09-27T10:59:58.610325",
     "exception": false,
     "start_time": "2021-09-27T10:59:58.440945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del mat1,mat2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6994d82d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:58.679147Z",
     "iopub.status.busy": "2021-09-27T10:59:58.678408Z",
     "iopub.status.idle": "2021-09-27T10:59:59.637003Z",
     "shell.execute_reply": "2021-09-27T10:59:59.636499Z",
     "shell.execute_reply.started": "2021-09-26T03:34:58.275209Z"
    },
    "papermill": {
     "duration": 0.995418,
     "end_time": "2021-09-27T10:59:59.637167",
     "exception": false,
     "start_time": "2021-09-27T10:59:58.641749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=train[~(train[\"stock_id\"]==31)]\n",
    "# train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c3cc0bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T10:59:59.715425Z",
     "iopub.status.busy": "2021-09-27T10:59:59.714559Z",
     "iopub.status.idle": "2021-09-27T11:00:00.749092Z",
     "shell.execute_reply": "2021-09-27T11:00:00.748337Z",
     "shell.execute_reply.started": "2021-09-26T05:03:31.783462Z"
    },
    "papermill": {
     "duration": 1.078097,
     "end_time": "2021-09-27T11:00:00.749266",
     "exception": false,
     "start_time": "2021-09-27T10:59:59.671169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setting param\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "# Russia\n",
    "seed0=31\n",
    "params0 = {\n",
    "    'objective': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_depth': -1,\n",
    "    'max_bin':100,\n",
    "    'min_data_in_leaf':500,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.72,\n",
    "    'subsample_freq': 3,\n",
    "    'feature_fraction': 0.5,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 1.0,\n",
    "    'categorical_column':[0],\n",
    "    'seed':seed0,\n",
    "    'feature_fraction_seed': seed0,\n",
    "    'bagging_seed': seed0,\n",
    "    'drop_seed': seed0,\n",
    "    'data_random_seed': seed0,\n",
    "    'n_jobs':-1,\n",
    "    'verbose': -1}\n",
    "# Germany\n",
    "seed1=42\n",
    "params1 = {\n",
    "        'learning_rate': 0.1,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 800,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 4,\n",
    "        'categorical_column':[0],\n",
    "        'seed': seed1,\n",
    "        'feature_fraction_seed': seed1,\n",
    "        'bagging_seed': seed1,\n",
    "        'drop_seed': seed1,\n",
    "        'data_random_seed': seed1,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs':-1,\n",
    "    }\n",
    "\n",
    "# Taiwan\n",
    "seed2=38\n",
    "params2 = {\n",
    "        'learning_rate': 0.05,        \n",
    "        'lambda_l1': 0.2,\n",
    "        'lambda_l2': 0.7,\n",
    "        'num_leaves': 800,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 60,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 10,\n",
    "        'categorical_column':[0],\n",
    "        'seed': seed2,\n",
    "        'feature_fraction_seed': seed2,\n",
    "        'bagging_seed': seed2,\n",
    "        'drop_seed': seed2,\n",
    "        'data_random_seed': seed2,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs':-1,\n",
    "    }\n",
    "# Japan\n",
    "seed3=66\n",
    "params3 = {\n",
    "        'learning_rate': 0.03,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 1200,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 30,\n",
    "        'categorical_column':[0],\n",
    "        'seed': seed3,\n",
    "        'feature_fraction_seed': seed3,\n",
    "        'bagging_seed': seed3,\n",
    "        'drop_seed': seed3,\n",
    "        'data_random_seed': seed3,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs':-1,\n",
    "    }\n",
    "\n",
    "# China\n",
    "seed4=88\n",
    "params4 = {\n",
    "        'learning_rate': 0.15,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 500,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 50,\n",
    "        'min_data_in_leaf': 500,\n",
    "        'max_depth': 30,\n",
    "        'categorical_column':[0],\n",
    "        'seed': seed4,\n",
    "        'feature_fraction_seed': seed4,\n",
    "        'bagging_seed': seed4,\n",
    "        'drop_seed': seed4,\n",
    "        'data_random_seed': seed4,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs':-1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "506b7e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T11:00:00.825558Z",
     "iopub.status.busy": "2021-09-27T11:00:00.824584Z",
     "iopub.status.idle": "2021-09-27T11:00:00.827714Z",
     "shell.execute_reply": "2021-09-27T11:00:00.827271Z",
     "shell.execute_reply.started": "2021-09-26T03:35:00.37964Z"
    },
    "papermill": {
     "duration": 0.046055,
     "end_time": "2021-09-27T11:00:00.827861",
     "exception": false,
     "start_time": "2021-09-27T11:00:00.781806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "def train_and_evaluate_lgb(train, test, params,boost=1000):\n",
    "    # Hyperparammeters (just basic)\n",
    "    \n",
    "    features = [col for col in train.columns if col not in {\"time_id\", \"target\", \"row_id\"}]\n",
    "    y = train['target']\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 31, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = train.iloc[trn_ind], train.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train[features], y_train, weight = train_weights)\n",
    "        val_dataset = lgb.Dataset(x_val[features], y_val, weight = val_weights)\n",
    "        model = lgb.train(params = params,\n",
    "                          num_boost_round=boost,\n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          verbose_eval = 250,\n",
    "                          early_stopping_rounds=30,\n",
    "                          feval = feval_rmspe)\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val[features])\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(test[features]) / 5\n",
    "    rmspe_score = rmspe(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    lgb.plot_importance(model,max_num_features=20)\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aa42d13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T11:00:00.897536Z",
     "iopub.status.busy": "2021-09-27T11:00:00.896406Z",
     "iopub.status.idle": "2021-09-27T11:12:03.398669Z",
     "shell.execute_reply": "2021-09-27T11:12:03.399168Z",
     "shell.execute_reply.started": "2021-09-26T03:35:00.396643Z"
    },
    "papermill": {
     "duration": 722.540631,
     "end_time": "2021-09-27T11:12:03.399386",
     "exception": false,
     "start_time": "2021-09-27T11:00:00.858755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000427305\ttraining's RMSPE: 0.196579\tvalid_1's rmse: 0.000433607\tvalid_1's RMSPE: 0.199874\n",
      "[500]\ttraining's rmse: 0.000405095\ttraining's RMSPE: 0.186361\tvalid_1's rmse: 0.000416623\tvalid_1's RMSPE: 0.192045\n",
      "[750]\ttraining's rmse: 0.00039219\ttraining's RMSPE: 0.180425\tvalid_1's rmse: 0.000408787\tvalid_1's RMSPE: 0.188433\n",
      "[1000]\ttraining's rmse: 0.000382842\ttraining's RMSPE: 0.176124\tvalid_1's rmse: 0.000404469\tvalid_1's RMSPE: 0.186443\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000382842\ttraining's RMSPE: 0.176124\tvalid_1's rmse: 0.000404469\tvalid_1's RMSPE: 0.186443\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000426894\ttraining's RMSPE: 0.196714\tvalid_1's rmse: 0.000434831\tvalid_1's RMSPE: 0.199115\n",
      "[500]\ttraining's rmse: 0.000404407\ttraining's RMSPE: 0.186352\tvalid_1's rmse: 0.000417869\tvalid_1's RMSPE: 0.191348\n",
      "[750]\ttraining's rmse: 0.000391708\ttraining's RMSPE: 0.1805\tvalid_1's rmse: 0.000410483\tvalid_1's RMSPE: 0.187966\n",
      "[1000]\ttraining's rmse: 0.00038223\ttraining's RMSPE: 0.176132\tvalid_1's rmse: 0.000405994\tvalid_1's RMSPE: 0.185911\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.00038223\ttraining's RMSPE: 0.176132\tvalid_1's rmse: 0.000405994\tvalid_1's RMSPE: 0.185911\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000426916\ttraining's RMSPE: 0.196401\tvalid_1's rmse: 0.000437398\tvalid_1's RMSPE: 0.201616\n",
      "[500]\ttraining's rmse: 0.000404726\ttraining's RMSPE: 0.186193\tvalid_1's rmse: 0.000420218\tvalid_1's RMSPE: 0.193697\n",
      "[750]\ttraining's rmse: 0.000391759\ttraining's RMSPE: 0.180227\tvalid_1's rmse: 0.000412533\tvalid_1's RMSPE: 0.190155\n",
      "[1000]\ttraining's rmse: 0.000382394\ttraining's RMSPE: 0.175919\tvalid_1's rmse: 0.000408086\tvalid_1's RMSPE: 0.188105\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000382394\ttraining's RMSPE: 0.175919\tvalid_1's rmse: 0.000408086\tvalid_1's RMSPE: 0.188105\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.00042848\ttraining's RMSPE: 0.197038\tvalid_1's rmse: 0.000431809\tvalid_1's RMSPE: 0.199373\n",
      "[500]\ttraining's rmse: 0.000405955\ttraining's RMSPE: 0.18668\tvalid_1's rmse: 0.000414423\tvalid_1's RMSPE: 0.191345\n",
      "[750]\ttraining's rmse: 0.00039289\ttraining's RMSPE: 0.180672\tvalid_1's rmse: 0.000406578\tvalid_1's RMSPE: 0.187723\n",
      "[1000]\ttraining's rmse: 0.000383357\ttraining's RMSPE: 0.176288\tvalid_1's rmse: 0.000402014\tvalid_1's RMSPE: 0.185616\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000383357\ttraining's RMSPE: 0.176288\tvalid_1's rmse: 0.000402014\tvalid_1's RMSPE: 0.185616\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000426488\ttraining's RMSPE: 0.196349\tvalid_1's rmse: 0.000440473\tvalid_1's RMSPE: 0.202437\n",
      "[500]\ttraining's rmse: 0.000404366\ttraining's RMSPE: 0.186164\tvalid_1's rmse: 0.000423511\tvalid_1's RMSPE: 0.194642\n",
      "[750]\ttraining's rmse: 0.000391486\ttraining's RMSPE: 0.180234\tvalid_1's rmse: 0.000415643\tvalid_1's RMSPE: 0.191026\n",
      "[1000]\ttraining's rmse: 0.000382054\ttraining's RMSPE: 0.175892\tvalid_1's rmse: 0.000411383\tvalid_1's RMSPE: 0.189068\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000382054\ttraining's RMSPE: 0.175892\tvalid_1's rmse: 0.000411383\tvalid_1's RMSPE: 0.189068\n",
      "Our out of folds RMSPE is 0.18703302688400472\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_lgb0= train_and_evaluate_lgb(train, test,params0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c087123e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T11:12:03.484883Z",
     "iopub.status.busy": "2021-09-27T11:12:03.484135Z",
     "iopub.status.idle": "2021-09-27T12:21:42.816984Z",
     "shell.execute_reply": "2021-09-27T12:21:42.816469Z",
     "shell.execute_reply.started": "2021-09-26T03:45:55.564331Z"
    },
    "papermill": {
     "duration": 4179.376608,
     "end_time": "2021-09-27T12:21:42.817160",
     "exception": false,
     "start_time": "2021-09-27T11:12:03.440552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000433251\ttraining's RMSPE: 0.199314\tvalid_1's rmse: 0.000438898\tvalid_1's RMSPE: 0.202313\n",
      "[500]\ttraining's rmse: 0.00041331\ttraining's RMSPE: 0.190141\tvalid_1's rmse: 0.000422261\tvalid_1's RMSPE: 0.194644\n",
      "[750]\ttraining's rmse: 0.000401946\ttraining's RMSPE: 0.184913\tvalid_1's rmse: 0.000414323\tvalid_1's RMSPE: 0.190985\n",
      "[1000]\ttraining's rmse: 0.000393402\ttraining's RMSPE: 0.180982\tvalid_1's rmse: 0.000408809\tvalid_1's RMSPE: 0.188443\n",
      "[1250]\ttraining's rmse: 0.000386967\ttraining's RMSPE: 0.178021\tvalid_1's rmse: 0.000405176\tvalid_1's RMSPE: 0.186768\n",
      "[1500]\ttraining's rmse: 0.000381633\ttraining's RMSPE: 0.175568\tvalid_1's rmse: 0.00040281\tvalid_1's RMSPE: 0.185678\n",
      "[1750]\ttraining's rmse: 0.000377138\ttraining's RMSPE: 0.1735\tvalid_1's rmse: 0.000400891\tvalid_1's RMSPE: 0.184793\n",
      "[2000]\ttraining's rmse: 0.000373211\ttraining's RMSPE: 0.171693\tvalid_1's rmse: 0.000399827\tvalid_1's RMSPE: 0.184303\n",
      "[2250]\ttraining's rmse: 0.000369337\ttraining's RMSPE: 0.169911\tvalid_1's rmse: 0.000398823\tvalid_1's RMSPE: 0.18384\n",
      "[2500]\ttraining's rmse: 0.000365823\ttraining's RMSPE: 0.168294\tvalid_1's rmse: 0.000397938\tvalid_1's RMSPE: 0.183432\n",
      "[2750]\ttraining's rmse: 0.000362542\ttraining's RMSPE: 0.166785\tvalid_1's rmse: 0.000397405\tvalid_1's RMSPE: 0.183186\n",
      "[3000]\ttraining's rmse: 0.000359549\ttraining's RMSPE: 0.165408\tvalid_1's rmse: 0.000396736\tvalid_1's RMSPE: 0.182878\n",
      "Early stopping, best iteration is:\n",
      "[3095]\ttraining's rmse: 0.000358425\ttraining's RMSPE: 0.164891\tvalid_1's rmse: 0.000396568\tvalid_1's RMSPE: 0.182801\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000432428\ttraining's RMSPE: 0.199264\tvalid_1's rmse: 0.000439315\tvalid_1's RMSPE: 0.201169\n",
      "[500]\ttraining's rmse: 0.00041281\ttraining's RMSPE: 0.190224\tvalid_1's rmse: 0.000423903\tvalid_1's RMSPE: 0.194111\n",
      "[750]\ttraining's rmse: 0.000401165\ttraining's RMSPE: 0.184858\tvalid_1's rmse: 0.000415722\tvalid_1's RMSPE: 0.190365\n",
      "[1000]\ttraining's rmse: 0.000392484\ttraining's RMSPE: 0.180858\tvalid_1's rmse: 0.000410499\tvalid_1's RMSPE: 0.187974\n",
      "[1250]\ttraining's rmse: 0.000386243\ttraining's RMSPE: 0.177982\tvalid_1's rmse: 0.000407255\tvalid_1's RMSPE: 0.186488\n",
      "[1500]\ttraining's rmse: 0.000381065\ttraining's RMSPE: 0.175595\tvalid_1's rmse: 0.000405066\tvalid_1's RMSPE: 0.185486\n",
      "[1750]\ttraining's rmse: 0.000376448\ttraining's RMSPE: 0.173468\tvalid_1's rmse: 0.000403381\tvalid_1's RMSPE: 0.184714\n",
      "[2000]\ttraining's rmse: 0.000372267\ttraining's RMSPE: 0.171541\tvalid_1's rmse: 0.000402058\tvalid_1's RMSPE: 0.184108\n",
      "[2250]\ttraining's rmse: 0.000368546\ttraining's RMSPE: 0.169827\tvalid_1's rmse: 0.000401208\tvalid_1's RMSPE: 0.183719\n",
      "Early stopping, best iteration is:\n",
      "[2268]\ttraining's rmse: 0.000368254\ttraining's RMSPE: 0.169692\tvalid_1's rmse: 0.000401157\tvalid_1's RMSPE: 0.183695\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000432321\ttraining's RMSPE: 0.198888\tvalid_1's rmse: 0.000442688\tvalid_1's RMSPE: 0.204055\n",
      "[500]\ttraining's rmse: 0.000413285\ttraining's RMSPE: 0.19013\tvalid_1's rmse: 0.000427117\tvalid_1's RMSPE: 0.196877\n",
      "[750]\ttraining's rmse: 0.000400959\ttraining's RMSPE: 0.18446\tvalid_1's rmse: 0.000418045\tvalid_1's RMSPE: 0.192696\n",
      "[1000]\ttraining's rmse: 0.000393106\ttraining's RMSPE: 0.180847\tvalid_1's rmse: 0.000413355\tvalid_1's RMSPE: 0.190534\n",
      "[1250]\ttraining's rmse: 0.000386376\ttraining's RMSPE: 0.177751\tvalid_1's rmse: 0.000409768\tvalid_1's RMSPE: 0.18888\n",
      "[1500]\ttraining's rmse: 0.000381039\ttraining's RMSPE: 0.175295\tvalid_1's rmse: 0.000407232\tvalid_1's RMSPE: 0.187711\n",
      "[1750]\ttraining's rmse: 0.00037635\ttraining's RMSPE: 0.173138\tvalid_1's rmse: 0.000405297\tvalid_1's RMSPE: 0.186819\n",
      "[2000]\ttraining's rmse: 0.000372337\ttraining's RMSPE: 0.171292\tvalid_1's rmse: 0.000404045\tvalid_1's RMSPE: 0.186242\n",
      "[2250]\ttraining's rmse: 0.000368573\ttraining's RMSPE: 0.169561\tvalid_1's rmse: 0.000402933\tvalid_1's RMSPE: 0.18573\n",
      "[2500]\ttraining's rmse: 0.000365169\ttraining's RMSPE: 0.167995\tvalid_1's rmse: 0.000402277\tvalid_1's RMSPE: 0.185428\n",
      "Early stopping, best iteration is:\n",
      "[2511]\ttraining's rmse: 0.000365042\ttraining's RMSPE: 0.167936\tvalid_1's rmse: 0.00040226\tvalid_1's RMSPE: 0.18542\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.00043334\ttraining's RMSPE: 0.199273\tvalid_1's rmse: 0.000435798\tvalid_1's RMSPE: 0.201214\n",
      "[500]\ttraining's rmse: 0.000414131\ttraining's RMSPE: 0.190439\tvalid_1's rmse: 0.000420419\tvalid_1's RMSPE: 0.194114\n",
      "[750]\ttraining's rmse: 0.000402233\ttraining's RMSPE: 0.184968\tvalid_1's rmse: 0.000411657\tvalid_1's RMSPE: 0.190068\n",
      "[1000]\ttraining's rmse: 0.000393889\ttraining's RMSPE: 0.181131\tvalid_1's rmse: 0.000406377\tvalid_1's RMSPE: 0.18763\n",
      "[1250]\ttraining's rmse: 0.000387583\ttraining's RMSPE: 0.178231\tvalid_1's rmse: 0.00040315\tvalid_1's RMSPE: 0.18614\n",
      "[1500]\ttraining's rmse: 0.000382027\ttraining's RMSPE: 0.175676\tvalid_1's rmse: 0.0004006\tvalid_1's RMSPE: 0.184963\n",
      "[1750]\ttraining's rmse: 0.000377423\ttraining's RMSPE: 0.173559\tvalid_1's rmse: 0.000398906\tvalid_1's RMSPE: 0.184181\n",
      "[2000]\ttraining's rmse: 0.000373204\ttraining's RMSPE: 0.171619\tvalid_1's rmse: 0.000397638\tvalid_1's RMSPE: 0.183595\n",
      "[2250]\ttraining's rmse: 0.000369493\ttraining's RMSPE: 0.169913\tvalid_1's rmse: 0.000396608\tvalid_1's RMSPE: 0.18312\n",
      "[2500]\ttraining's rmse: 0.000365931\ttraining's RMSPE: 0.168275\tvalid_1's rmse: 0.00039581\tvalid_1's RMSPE: 0.182751\n",
      "[2750]\ttraining's rmse: 0.000362578\ttraining's RMSPE: 0.166733\tvalid_1's rmse: 0.000395042\tvalid_1's RMSPE: 0.182397\n",
      "Early stopping, best iteration is:\n",
      "[2772]\ttraining's rmse: 0.00036227\ttraining's RMSPE: 0.166591\tvalid_1's rmse: 0.000394975\tvalid_1's RMSPE: 0.182366\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000431086\ttraining's RMSPE: 0.198466\tvalid_1's rmse: 0.000444733\tvalid_1's RMSPE: 0.204395\n",
      "[500]\ttraining's rmse: 0.000412421\ttraining's RMSPE: 0.189872\tvalid_1's rmse: 0.000429167\tvalid_1's RMSPE: 0.197241\n",
      "[750]\ttraining's rmse: 0.000400704\ttraining's RMSPE: 0.184478\tvalid_1's rmse: 0.000420595\tvalid_1's RMSPE: 0.193301\n",
      "[1000]\ttraining's rmse: 0.000392731\ttraining's RMSPE: 0.180807\tvalid_1's rmse: 0.00041544\tvalid_1's RMSPE: 0.190932\n",
      "[1250]\ttraining's rmse: 0.000386087\ttraining's RMSPE: 0.177748\tvalid_1's rmse: 0.000412029\tvalid_1's RMSPE: 0.189365\n",
      "[1500]\ttraining's rmse: 0.000380772\ttraining's RMSPE: 0.175301\tvalid_1's rmse: 0.000409718\tvalid_1's RMSPE: 0.188303\n",
      "[1750]\ttraining's rmse: 0.000376358\ttraining's RMSPE: 0.173269\tvalid_1's rmse: 0.000408305\tvalid_1's RMSPE: 0.187653\n",
      "[2000]\ttraining's rmse: 0.000372172\ttraining's RMSPE: 0.171342\tvalid_1's rmse: 0.000407104\tvalid_1's RMSPE: 0.187101\n",
      "[2250]\ttraining's rmse: 0.000368507\ttraining's RMSPE: 0.169655\tvalid_1's rmse: 0.000406535\tvalid_1's RMSPE: 0.18684\n",
      "Early stopping, best iteration is:\n",
      "[2270]\ttraining's rmse: 0.000368242\ttraining's RMSPE: 0.169533\tvalid_1's rmse: 0.000406422\tvalid_1's RMSPE: 0.186787\n",
      "Our out of folds RMSPE is 0.18422128856164877\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000392204\ttraining's RMSPE: 0.180431\tvalid_1's rmse: 0.000415602\tvalid_1's RMSPE: 0.191574\n",
      "[500]\ttraining's rmse: 0.000369635\ttraining's RMSPE: 0.170048\tvalid_1's rmse: 0.000403787\tvalid_1's RMSPE: 0.186128\n",
      "[750]\ttraining's rmse: 0.000355856\ttraining's RMSPE: 0.163709\tvalid_1's rmse: 0.000399178\tvalid_1's RMSPE: 0.184004\n",
      "[1000]\ttraining's rmse: 0.000344174\ttraining's RMSPE: 0.158335\tvalid_1's rmse: 0.000396833\tvalid_1's RMSPE: 0.182923\n",
      "[1250]\ttraining's rmse: 0.000335398\ttraining's RMSPE: 0.154298\tvalid_1's rmse: 0.000395667\tvalid_1's RMSPE: 0.182385\n",
      "Early stopping, best iteration is:\n",
      "[1369]\ttraining's rmse: 0.000331461\ttraining's RMSPE: 0.152486\tvalid_1's rmse: 0.000395426\tvalid_1's RMSPE: 0.182274\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000391322\ttraining's RMSPE: 0.180322\tvalid_1's rmse: 0.000416248\tvalid_1's RMSPE: 0.190606\n",
      "[500]\ttraining's rmse: 0.000368453\ttraining's RMSPE: 0.169784\tvalid_1's rmse: 0.000405117\tvalid_1's RMSPE: 0.185509\n",
      "[750]\ttraining's rmse: 0.000354577\ttraining's RMSPE: 0.16339\tvalid_1's rmse: 0.000400918\tvalid_1's RMSPE: 0.183586\n",
      "[1000]\ttraining's rmse: 0.0003439\ttraining's RMSPE: 0.15847\tvalid_1's rmse: 0.000399212\tvalid_1's RMSPE: 0.182805\n",
      "[1250]\ttraining's rmse: 0.000334882\ttraining's RMSPE: 0.154314\tvalid_1's rmse: 0.000398211\tvalid_1's RMSPE: 0.182347\n",
      "[1500]\ttraining's rmse: 0.000326573\ttraining's RMSPE: 0.150485\tvalid_1's rmse: 0.00039756\tvalid_1's RMSPE: 0.182048\n",
      "Early stopping, best iteration is:\n",
      "[1592]\ttraining's rmse: 0.000323546\ttraining's RMSPE: 0.149091\tvalid_1's rmse: 0.000397429\tvalid_1's RMSPE: 0.181989\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000391594\ttraining's RMSPE: 0.180151\tvalid_1's rmse: 0.000419404\tvalid_1's RMSPE: 0.193322\n",
      "[500]\ttraining's rmse: 0.000369465\ttraining's RMSPE: 0.169971\tvalid_1's rmse: 0.000407999\tvalid_1's RMSPE: 0.188065\n",
      "[750]\ttraining's rmse: 0.000355596\ttraining's RMSPE: 0.163591\tvalid_1's rmse: 0.000403837\tvalid_1's RMSPE: 0.186147\n",
      "[1000]\ttraining's rmse: 0.000344058\ttraining's RMSPE: 0.158283\tvalid_1's rmse: 0.000401556\tvalid_1's RMSPE: 0.185095\n",
      "Early stopping, best iteration is:\n",
      "[1020]\ttraining's rmse: 0.000343311\ttraining's RMSPE: 0.157939\tvalid_1's rmse: 0.000401448\tvalid_1's RMSPE: 0.185045\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000392076\ttraining's RMSPE: 0.180297\tvalid_1's rmse: 0.000412089\tvalid_1's RMSPE: 0.190268\n",
      "[500]\ttraining's rmse: 0.000370233\ttraining's RMSPE: 0.170253\tvalid_1's rmse: 0.000401356\tvalid_1's RMSPE: 0.185312\n",
      "[750]\ttraining's rmse: 0.000356081\ttraining's RMSPE: 0.163745\tvalid_1's rmse: 0.000396986\tvalid_1's RMSPE: 0.183294\n",
      "[1000]\ttraining's rmse: 0.000345223\ttraining's RMSPE: 0.158752\tvalid_1's rmse: 0.000395071\tvalid_1's RMSPE: 0.18241\n",
      "[1250]\ttraining's rmse: 0.000336152\ttraining's RMSPE: 0.154581\tvalid_1's rmse: 0.000393907\tvalid_1's RMSPE: 0.181873\n",
      "[1500]\ttraining's rmse: 0.000328251\ttraining's RMSPE: 0.150947\tvalid_1's rmse: 0.000393143\tvalid_1's RMSPE: 0.18152\n",
      "Early stopping, best iteration is:\n",
      "[1694]\ttraining's rmse: 0.000321828\ttraining's RMSPE: 0.147994\tvalid_1's rmse: 0.000392821\tvalid_1's RMSPE: 0.181371\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[250]\ttraining's rmse: 0.000391381\ttraining's RMSPE: 0.180186\tvalid_1's rmse: 0.000420898\tvalid_1's RMSPE: 0.193441\n",
      "[500]\ttraining's rmse: 0.000368964\ttraining's RMSPE: 0.169865\tvalid_1's rmse: 0.000409689\tvalid_1's RMSPE: 0.188289\n",
      "[750]\ttraining's rmse: 0.000354743\ttraining's RMSPE: 0.163318\tvalid_1's rmse: 0.000405639\tvalid_1's RMSPE: 0.186428\n",
      "[1000]\ttraining's rmse: 0.000343309\ttraining's RMSPE: 0.158054\tvalid_1's rmse: 0.000403704\tvalid_1's RMSPE: 0.185538\n",
      "[1250]\ttraining's rmse: 0.00033403\ttraining's RMSPE: 0.153782\tvalid_1's rmse: 0.000402727\tvalid_1's RMSPE: 0.18509\n",
      "Early stopping, best iteration is:\n",
      "[1382]\ttraining's rmse: 0.000329377\ttraining's RMSPE: 0.15164\tvalid_1's rmse: 0.000402436\tvalid_1's RMSPE: 0.184956\n",
      "Our out of folds RMSPE is 0.18313365245454796\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Traing and evaluate\n",
    "# predictions_lgb0= train_and_evaluate_lgb(train, test,params0)\n",
    "predictions_lgb1= train_and_evaluate_lgb(train, test,params1, boost=10000)\n",
    "predictions_lgb2= train_and_evaluate_lgb(train, test,params2, boost=10000)\n",
    "# predictions_lgb3= train_and_evaluate_lgb(train, test,params3, boost=10000)\n",
    "# predictions_lgb4= train_and_evaluate_lgb(train, test,params4, boost=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "181fb43e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:21:42.957816Z",
     "iopub.status.busy": "2021-09-27T12:21:42.957111Z",
     "iopub.status.idle": "2021-09-27T12:21:42.959670Z",
     "shell.execute_reply": "2021-09-27T12:21:42.960213Z",
     "shell.execute_reply.started": "2021-09-26T05:03:36.004144Z"
    },
    "papermill": {
     "duration": 0.075753,
     "end_time": "2021-09-27T12:21:42.960383",
     "exception": false,
     "start_time": "2021-09-27T12:21:42.884630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictions_lgb3= train_and_evaluate_lgb(train, test,params3, boost=10000)\n",
    "# predictions_lgb4= train_and_evaluate_lgb(train, test,params4, boost=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b388148d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:21:43.098318Z",
     "iopub.status.busy": "2021-09-27T12:21:43.097627Z",
     "iopub.status.idle": "2021-09-27T12:21:43.100910Z",
     "shell.execute_reply": "2021-09-27T12:21:43.101417Z"
    },
    "papermill": {
     "duration": 0.074758,
     "end_time": "2021-09-27T12:21:43.101604",
     "exception": false,
     "start_time": "2021-09-27T12:21:43.026846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test['target'] = predictions_lgb*0.5 + predictions_lgb2*0.5\n",
    "# preds_lgb = predictions_lgb*0.5 + predictions_lgb2*0.5\n",
    "# test[['row_id', 'target']].to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9312742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:21:43.239588Z",
     "iopub.status.busy": "2021-09-27T12:21:43.238966Z",
     "iopub.status.idle": "2021-09-27T12:21:43.243949Z",
     "shell.execute_reply": "2021-09-27T12:21:43.243475Z",
     "shell.execute_reply.started": "2021-09-26T05:23:09.072358Z"
    },
    "papermill": {
     "duration": 0.07472,
     "end_time": "2021-09-27T12:21:43.244113",
     "exception": false,
     "start_time": "2021-09-27T12:21:43.169393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_submissions = '/'\n",
    "target_name = 'target'\n",
    "scores_folds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01220b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:21:43.403921Z",
     "iopub.status.busy": "2021-09-27T12:21:43.403193Z",
     "iopub.status.idle": "2021-09-27T12:22:55.445900Z",
     "shell.execute_reply": "2021-09-27T12:22:55.446381Z",
     "shell.execute_reply.started": "2021-09-26T05:23:09.51583Z"
    },
    "papermill": {
     "duration": 72.1357,
     "end_time": "2021-09-27T12:22:55.446583",
     "exception": false,
     "start_time": "2021-09-27T12:21:43.310883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "[81]\n",
      "[8, 80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:164: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:168: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "# kfold based on the knn++ algorithm\n",
    "\n",
    "out_train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "out_train = out_train.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "#out_train[out_train.isna().any(axis=1)]\n",
    "out_train = out_train.fillna(out_train.mean())\n",
    "out_train.head()\n",
    "\n",
    "# code to add the just the read data after first execution\n",
    "\n",
    "# data separation based on knn ++\n",
    "nfolds = 5 # number of folds\n",
    "index = []\n",
    "totDist = []\n",
    "values = []\n",
    "# generates a matriz with the values of \n",
    "mat = out_train.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "mat = scaler.fit_transform(mat)\n",
    "\n",
    "nind = int(mat.shape[0]/nfolds) # number of individuals\n",
    "\n",
    "# adds index in the last column\n",
    "mat = np.c_[mat,np.arange(mat.shape[0])]\n",
    "\n",
    "\n",
    "lineNumber = np.random.choice(np.array(mat.shape[0]), size=nfolds, replace=False)\n",
    "\n",
    "lineNumber = np.sort(lineNumber)[::-1]\n",
    "\n",
    "for n in range(nfolds):\n",
    "    totDist.append(np.zeros(mat.shape[0]-nfolds))\n",
    "\n",
    "# saves index\n",
    "for n in range(nfolds):\n",
    "    \n",
    "    values.append([lineNumber[n]])    \n",
    "\n",
    "\n",
    "s=[]\n",
    "for n in range(nfolds):\n",
    "    s.append(mat[lineNumber[n],:])\n",
    "    \n",
    "    mat = np.delete(mat, obj=lineNumber[n], axis=0)\n",
    "\n",
    "for n in range(nind-1):    \n",
    "\n",
    "    luck = np.random.uniform(0,1,nfolds)\n",
    "    \n",
    "    for cycle in range(nfolds):\n",
    "         # saves the values of index           \n",
    "\n",
    "        s[cycle] = np.matlib.repmat(s[cycle], mat.shape[0], 1)\n",
    "\n",
    "        sumDist = np.sum( (mat[:,:-1] - s[cycle][:,:-1])**2 , axis=1)   \n",
    "        totDist[cycle] += sumDist        \n",
    "                \n",
    "        # probabilities\n",
    "        f = totDist[cycle]/np.sum(totDist[cycle]) # normalizing the totdist\n",
    "        j = 0\n",
    "        kn = 0\n",
    "        for val in f:\n",
    "            j += val        \n",
    "            if (j > luck[cycle]): # the column was selected\n",
    "                break\n",
    "            kn +=1\n",
    "        lineNumber[cycle] = kn\n",
    "        \n",
    "        # delete line of the value added    \n",
    "        for n_iter in range(nfolds):\n",
    "            \n",
    "            totDist[n_iter] = np.delete(totDist[n_iter],obj=lineNumber[cycle], axis=0)\n",
    "            j= 0\n",
    "        \n",
    "        s[cycle] = mat[lineNumber[cycle],:]\n",
    "        values[cycle].append(int(mat[lineNumber[cycle],-1]))\n",
    "        mat = np.delete(mat, obj=lineNumber[cycle], axis=0)\n",
    "\n",
    "\n",
    "for n_mod in range(nfolds):\n",
    "    values[n_mod] = out_train.index[values[n_mod]]\n",
    "def root_mean_squared_per_error(y_true, y_pred):\n",
    "         return K.sqrt(K.mean(K.square( (y_true - y_pred)/ y_true )))\n",
    "    \n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=0,\n",
    "    mode='min',restore_best_weights=True)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=7, verbose=0,\n",
    "    mode='min')\n",
    "colNames = list(train)\n",
    "\n",
    "colNames.remove('time_id')\n",
    "colNames.remove('target')\n",
    "colNames.remove('row_id')\n",
    "colNames.remove('stock_id')\n",
    "train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "qt_train = []\n",
    "\n",
    "for col in colNames:\n",
    "    #print(col)\n",
    "    qt = QuantileTransformer(random_state=21,n_quantiles=2000, output_distribution='normal')\n",
    "    train[col] = qt.fit_transform(train[[col]])\n",
    "    test[col] = qt.transform(test[[col]])    \n",
    "    qt_train.append(qt)\n",
    "from sklearn.cluster import KMeans\n",
    "# making agg features\n",
    "\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()\n",
    "\n",
    "matTest = []\n",
    "mat = []\n",
    "kmeans = []\n",
    "#mat2 #= mat1.pivot(index='time_id', columns='stock_idmat2\n",
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "090ef942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:22:55.597596Z",
     "iopub.status.busy": "2021-09-27T12:22:55.596801Z",
     "iopub.status.idle": "2021-09-27T12:23:10.408634Z",
     "shell.execute_reply": "2021-09-27T12:23:10.408129Z",
     "shell.execute_reply.started": "2021-09-26T05:24:16.530559Z"
    },
    "papermill": {
     "duration": 14.892809,
     "end_time": "2021-09-27T12:23:10.408784",
     "exception": false,
     "start_time": "2021-09-27T12:22:55.515975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((425102, 382), (3, 381))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_diff_size_sum_0c1',\n",
    "     'total_diff_size_sum_1c1', \n",
    "     'total_diff_size_sum_3c1',\n",
    "     'total_diff_size_sum_4c1', \n",
    "     'total_diff_size_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'Bid_spread_sum_0c1',\n",
    "     'Bid_spread_sum_1c1',\n",
    "     'Bid_spread_sum_3c1',\n",
    "     'Bid_spread_sum_4c1',\n",
    "     'Bid_spread_sum_6c1',       \n",
    "     'Ask_spread_sum_0c1',\n",
    "     'Ask_spread_sum_1c1',\n",
    "     'Ask_spread_sum_3c1',\n",
    "     'Ask_spread_sum_4c1',\n",
    "     'Ask_spread_sum_6c1',   \n",
    "     'total_size_sum_0c1',\n",
    "     'total_size_sum_1c1',\n",
    "     'total_size_sum_3c1',\n",
    "     'total_size_sum_4c1',\n",
    "     'total_size_sum_6c1',       \n",
    "     'BidAskSpread_sum_0c1',\n",
    "     'BidAskSpread_sum_1c1',\n",
    "     'BidAskSpread_sum_3c1',\n",
    "     'BidAskSpread_sum_4c1',\n",
    "     'BidAskSpread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] \n",
    "\n",
    "train = pd.merge(train,mat1[nnn],how='left',on='time_id')\n",
    "test = pd.merge(test,mat2[nnn],how='left',on='time_id')\n",
    "mat1= []\n",
    "mat2= []\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48a5bc4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:23:10.555617Z",
     "iopub.status.busy": "2021-09-27T12:23:10.554779Z",
     "iopub.status.idle": "2021-09-27T12:23:10.572937Z",
     "shell.execute_reply": "2021-09-27T12:23:10.572347Z",
     "shell.execute_reply.started": "2021-09-26T05:26:12.294579Z"
    },
    "papermill": {
     "duration": 0.095745,
     "end_time": "2021-09-27T12:23:10.573108",
     "exception": false,
     "start_time": "2021-09-27T12:23:10.477363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://bignerdranch.com/blog/implementing-swish-activation-function-in-keras/\n",
    "from keras.backend import sigmoid\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "hidden_units = (128,64,32)\n",
    "stock_embedding_size = 24\n",
    "\n",
    "cat_data = train['stock_id']\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n",
    "    num_input = keras.Input(shape=(378,), name='num_data')\n",
    "\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size, \n",
    "                                           input_length=1, name='stock_embedding')(stock_id_input)\n",
    "    stock_flattened = keras.layers.Flatten()(stock_embedded)\n",
    "    out = keras.layers.Concatenate()([stock_flattened, num_input])\n",
    "    \n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "\n",
    "        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n",
    "        \n",
    "\n",
    "    #out = keras.layers.Concatenate()([out, num_input])\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "    \n",
    "    model = keras.Model(\n",
    "    inputs = [stock_id_input, num_input],\n",
    "    outputs = out,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6e5204c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:23:10.729273Z",
     "iopub.status.busy": "2021-09-27T12:23:10.728513Z",
     "iopub.status.idle": "2021-09-27T12:38:11.943973Z",
     "shell.execute_reply": "2021-09-27T12:38:11.944760Z"
    },
    "papermill": {
     "duration": 901.303078,
     "end_time": "2021-09-27T12:38:11.944948",
     "exception": false,
     "start_time": "2021-09-27T12:23:10.641870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/5\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 28.0412 - val_loss: 1.8521\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 1.1165 - val_loss: 0.6277\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.6174 - val_loss: 0.7320\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.4863 - val_loss: 0.3427\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2961 - val_loss: 0.4233\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.3078 - val_loss: 0.2599\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2999 - val_loss: 0.2955\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.3201 - val_loss: 0.2481\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.3368 - val_loss: 0.3068\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.3052 - val_loss: 0.5769\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 5.6366 - val_loss: 0.3005\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.5416 - val_loss: 0.4321\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2667 - val_loss: 0.3199\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2435 - val_loss: 0.2983\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2412 - val_loss: 0.2317\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2389 - val_loss: 0.2507\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2419 - val_loss: 0.2527\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2440 - val_loss: 0.2106\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2379 - val_loss: 0.2276\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2426 - val_loss: 0.2229\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2367 - val_loss: 0.2723\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2620 - val_loss: 0.2736\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2379 - val_loss: 0.2235\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2398 - val_loss: 0.3271\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2345 - val_loss: 0.2375\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2074 - val_loss: 0.2064\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2035 - val_loss: 0.2079\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2042 - val_loss: 0.2056\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2031 - val_loss: 0.2244\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2067 - val_loss: 0.2096\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2032 - val_loss: 0.2062\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2039 - val_loss: 0.2057\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2042 - val_loss: 0.2104\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2045 - val_loss: 0.2070\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2043 - val_loss: 0.2136\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2022 - val_loss: 0.2040\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.2008 - val_loss: 0.2066\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2005 - val_loss: 0.2045\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2015 - val_loss: 0.2056\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2008 - val_loss: 0.2053\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2004 - val_loss: 0.2046\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2011 - val_loss: 0.2041\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2007 - val_loss: 0.2092\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2003 - val_loss: 0.2040\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1998 - val_loss: 0.2043\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1995 - val_loss: 0.2046\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2000 - val_loss: 0.2041\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1999 - val_loss: 0.2042\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2002 - val_loss: 0.2045\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2001 - val_loss: 0.2043\n",
      "Epoch 51/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1993 - val_loss: 0.2042\n",
      "Epoch 52/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1993 - val_loss: 0.2041\n",
      "Epoch 53/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1995 - val_loss: 0.2041\n",
      "Epoch 54/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1997 - val_loss: 0.2041\n",
      "Epoch 55/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1992 - val_loss: 0.2046\n",
      "Epoch 56/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1995 - val_loss: 0.2041\n",
      "Fold 1 NN: 0.20401\n",
      "CV 2/5\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 4s 17ms/step - loss: 22.8786 - val_loss: 1.4661\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.8926 - val_loss: 0.5340\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.6645 - val_loss: 0.3962\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.9295 - val_loss: 0.9045\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.7287 - val_loss: 0.6057\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.0215 - val_loss: 0.4837\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.3025 - val_loss: 0.3055\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2698 - val_loss: 0.2842\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2950 - val_loss: 0.2791\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.3059 - val_loss: 0.2329\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.3042 - val_loss: 0.4551\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.4388 - val_loss: 0.4369\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.3098 - val_loss: 0.3203\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.3059 - val_loss: 0.4141\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.3103 - val_loss: 0.2588\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.3532 - val_loss: 0.6261\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 3.2302 - val_loss: 0.3793\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2498 - val_loss: 0.2276\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2225 - val_loss: 0.2227\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2193 - val_loss: 0.2202\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2180 - val_loss: 0.2194\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2157 - val_loss: 0.2160\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2143 - val_loss: 0.2204\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2142 - val_loss: 0.2144\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2119 - val_loss: 0.2156\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2122 - val_loss: 0.2157\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2102 - val_loss: 0.2131\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2110 - val_loss: 0.2131\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2103 - val_loss: 0.2313\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2127 - val_loss: 0.2154\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2089 - val_loss: 0.2192\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2100 - val_loss: 0.2128\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2106 - val_loss: 0.2160\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2096 - val_loss: 0.2119\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2089 - val_loss: 0.2287\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2117 - val_loss: 0.2255\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2096 - val_loss: 0.2101\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2083 - val_loss: 0.2114\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2104 - val_loss: 0.2222\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2091 - val_loss: 0.2151\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2098 - val_loss: 0.2506\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2111 - val_loss: 0.2130\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2099 - val_loss: 0.2164\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2075 - val_loss: 0.2203\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2047 - val_loss: 0.2075\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2031 - val_loss: 0.2063\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2024 - val_loss: 0.2082\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2017 - val_loss: 0.2065\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2022 - val_loss: 0.2102\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2025 - val_loss: 0.2142\n",
      "Epoch 51/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2042 - val_loss: 0.2082\n",
      "Epoch 52/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2015 - val_loss: 0.2068\n",
      "Epoch 53/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2019 - val_loss: 0.2089\n",
      "Epoch 54/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2008 - val_loss: 0.2064\n",
      "Epoch 55/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2005 - val_loss: 0.2057\n",
      "Epoch 56/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2009 - val_loss: 0.2062\n",
      "Epoch 57/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2006 - val_loss: 0.2060\n",
      "Epoch 58/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2006 - val_loss: 0.2057\n",
      "Epoch 59/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2009 - val_loss: 0.2061\n",
      "Epoch 60/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2009 - val_loss: 0.2068\n",
      "Epoch 61/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2004 - val_loss: 0.2061\n",
      "Epoch 62/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2003 - val_loss: 0.2058\n",
      "Epoch 63/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2004 - val_loss: 0.2060\n",
      "Epoch 64/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2002 - val_loss: 0.2059\n",
      "Epoch 65/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2004 - val_loss: 0.2057\n",
      "Epoch 66/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1998 - val_loss: 0.2061\n",
      "Epoch 67/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2000 - val_loss: 0.2057\n",
      "Epoch 68/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1997 - val_loss: 0.2060\n",
      "Epoch 69/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2007 - val_loss: 0.2057\n",
      "Epoch 70/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2002 - val_loss: 0.2058\n",
      "Epoch 71/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2001 - val_loss: 0.2058\n",
      "Epoch 72/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2000 - val_loss: 0.2059\n",
      "Epoch 73/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2004 - val_loss: 0.2058\n",
      "Epoch 74/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2001 - val_loss: 0.2058\n",
      "Epoch 75/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1999 - val_loss: 0.2057\n",
      "Fold 2 NN: 0.20569\n",
      "CV 3/5\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 26.9816 - val_loss: 0.7361\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.7342 - val_loss: 0.8001\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.5694 - val_loss: 0.5597\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.5282 - val_loss: 0.4182\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 1.1071 - val_loss: 0.6723\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.4700 - val_loss: 0.3179\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.4635 - val_loss: 0.3387\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.4580 - val_loss: 0.4123\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.4557 - val_loss: 0.4976\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.4571 - val_loss: 7.1276\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 1.9049 - val_loss: 0.2181\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2196 - val_loss: 0.2133\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2260 - val_loss: 0.2167\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2240 - val_loss: 0.2456\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2292 - val_loss: 0.2114\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2324 - val_loss: 0.2454\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2392 - val_loss: 0.2327\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2455 - val_loss: 0.2901\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2475 - val_loss: 0.2146\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2463 - val_loss: 0.3374\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2561 - val_loss: 0.2709\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2479 - val_loss: 0.2219\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2041 - val_loss: 0.2068\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2016 - val_loss: 0.2071\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2006 - val_loss: 0.2190\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2032 - val_loss: 0.2061\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2016 - val_loss: 0.2064\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2015 - val_loss: 0.2139\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2019 - val_loss: 0.2073\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2030 - val_loss: 0.2322\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2051 - val_loss: 0.2131\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2011 - val_loss: 0.2152\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2022 - val_loss: 0.2080\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1985 - val_loss: 0.2055\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1978 - val_loss: 0.2061\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1980 - val_loss: 0.2058\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1981 - val_loss: 0.2057\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1974 - val_loss: 0.2085\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1982 - val_loss: 0.2063\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1984 - val_loss: 0.2062\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1977 - val_loss: 0.2067\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1973 - val_loss: 0.2057\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1972 - val_loss: 0.2061\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1969 - val_loss: 0.2057\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1975 - val_loss: 0.2056\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1969 - val_loss: 0.2057\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1964 - val_loss: 0.2058\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1970 - val_loss: 0.2059\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1970 - val_loss: 0.2057\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1970 - val_loss: 0.2057\n",
      "Epoch 51/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1962 - val_loss: 0.2057\n",
      "Epoch 52/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1966 - val_loss: 0.2057\n",
      "Epoch 53/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1972 - val_loss: 0.2057\n",
      "Epoch 54/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1969 - val_loss: 0.2059\n",
      "Fold 3 NN: 0.20548\n",
      "CV 4/5\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 4s 19ms/step - loss: 35.7714 - val_loss: 2.0134\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 1.2916 - val_loss: 0.7544\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.7247 - val_loss: 0.7585\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.6092 - val_loss: 0.5666\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.5656 - val_loss: 0.6165\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.5616 - val_loss: 0.4786\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.5438 - val_loss: 0.5268\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 1.0838 - val_loss: 0.5205\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.4429 - val_loss: 0.3652\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.4393 - val_loss: 0.3493\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.4201 - val_loss: 0.4207\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.4198 - val_loss: 0.4366\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.4112 - val_loss: 0.4778\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 1.0506 - val_loss: 0.2365\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2310 - val_loss: 0.2201\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2205 - val_loss: 0.2236\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2209 - val_loss: 0.2214\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2238 - val_loss: 0.2232\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2321 - val_loss: 0.2448\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2379 - val_loss: 0.2394\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2377 - val_loss: 0.4161\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2608 - val_loss: 0.3565\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2192 - val_loss: 0.2103\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2011 - val_loss: 0.2097\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2007 - val_loss: 0.2102\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2008 - val_loss: 0.2103\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2011 - val_loss: 0.2128\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2014 - val_loss: 0.2111\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2016 - val_loss: 0.2323\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2033 - val_loss: 0.2125\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2006 - val_loss: 0.2126\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1989 - val_loss: 0.2090\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1982 - val_loss: 0.2095\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1984 - val_loss: 0.2102\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1977 - val_loss: 0.2095\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1987 - val_loss: 0.2092\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1978 - val_loss: 0.2095\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1977 - val_loss: 0.2094\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1984 - val_loss: 0.2087\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1980 - val_loss: 0.2097\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1977 - val_loss: 0.2104\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1979 - val_loss: 0.2086\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1977 - val_loss: 0.2118\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1988 - val_loss: 0.2118\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1983 - val_loss: 0.2127\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1987 - val_loss: 0.2094\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1970 - val_loss: 0.2087\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1963 - val_loss: 0.2092\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1967 - val_loss: 0.2090\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1967 - val_loss: 0.2086\n",
      "Epoch 51/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1964 - val_loss: 0.2092\n",
      "Epoch 52/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1965 - val_loss: 0.2085\n",
      "Epoch 53/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1959 - val_loss: 0.2093\n",
      "Epoch 54/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1970 - val_loss: 0.2088\n",
      "Epoch 55/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1963 - val_loss: 0.2098\n",
      "Epoch 56/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1968 - val_loss: 0.2098\n",
      "Epoch 57/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1969 - val_loss: 0.2096\n",
      "Epoch 58/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1964 - val_loss: 0.2096\n",
      "Epoch 59/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1969 - val_loss: 0.2089\n",
      "Epoch 60/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1959 - val_loss: 0.2088\n",
      "Epoch 61/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1957 - val_loss: 0.2086\n",
      "Epoch 62/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1960 - val_loss: 0.2086\n",
      "Epoch 63/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1955 - val_loss: 0.2087\n",
      "Epoch 64/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1967 - val_loss: 0.2087\n",
      "Epoch 65/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1961 - val_loss: 0.2085\n",
      "Epoch 66/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1953 - val_loss: 0.2089\n",
      "Epoch 67/200\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.1956 - val_loss: 0.2086\n",
      "Epoch 68/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1954 - val_loss: 0.2085\n",
      "Epoch 69/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1952 - val_loss: 0.2086\n",
      "Epoch 70/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1962 - val_loss: 0.2085\n",
      "Epoch 71/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1954 - val_loss: 0.2086\n",
      "Epoch 72/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1958 - val_loss: 0.2085\n",
      "Epoch 73/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1954 - val_loss: 0.2085\n",
      "Epoch 74/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1955 - val_loss: 0.2086\n",
      "Epoch 75/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1958 - val_loss: 0.2086\n",
      "Epoch 76/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1956 - val_loss: 0.2085\n",
      "Epoch 77/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1952 - val_loss: 0.2086\n",
      "Epoch 78/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1952 - val_loss: 0.2086\n",
      "Epoch 79/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1958 - val_loss: 0.2086\n",
      "Epoch 80/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1956 - val_loss: 0.2086\n",
      "Epoch 81/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1952 - val_loss: 0.2086\n",
      "Epoch 82/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1951 - val_loss: 0.2085\n",
      "Epoch 83/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1955 - val_loss: 0.2086\n",
      "Epoch 84/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1955 - val_loss: 0.2085\n",
      "Epoch 85/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1951 - val_loss: 0.2086\n",
      "Fold 4 NN: 0.20845\n",
      "CV 5/5\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 18.7880 - val_loss: 0.3675\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.4126 - val_loss: 0.4559\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.3327 - val_loss: 0.3178\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.3469 - val_loss: 0.2966\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.3118 - val_loss: 0.4474\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.3227 - val_loss: 0.8172\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 3.7071 - val_loss: 0.3089\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2472 - val_loss: 0.2420\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2478 - val_loss: 0.2900\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2591 - val_loss: 0.2670\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2707 - val_loss: 0.2485\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2669 - val_loss: 0.4433\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2647 - val_loss: 0.2299\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2582 - val_loss: 0.2726\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2582 - val_loss: 0.2605\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2562 - val_loss: 0.2164\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2559 - val_loss: 0.2362\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2591 - val_loss: 0.2472\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.5669 - val_loss: 0.2199\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2323 - val_loss: 0.2549\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2285 - val_loss: 0.2367\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2329 - val_loss: 0.3044\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2307 - val_loss: 0.2429\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2049 - val_loss: 0.2097\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2001 - val_loss: 0.2111\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2004 - val_loss: 0.2104\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1995 - val_loss: 0.2185\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2012 - val_loss: 0.2099\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1991 - val_loss: 0.2272\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2037 - val_loss: 0.2127\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2004 - val_loss: 0.2116\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1984 - val_loss: 0.2087\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1979 - val_loss: 0.2101\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1976 - val_loss: 0.2086\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1981 - val_loss: 0.2108\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1982 - val_loss: 0.2096\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1987 - val_loss: 0.2101\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1980 - val_loss: 0.2085\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1970 - val_loss: 0.2089\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1979 - val_loss: 0.2104\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1979 - val_loss: 0.2090\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1973 - val_loss: 0.2089\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1970 - val_loss: 0.2087\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1969 - val_loss: 0.2086\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1964 - val_loss: 0.2085\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1964 - val_loss: 0.2083\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1966 - val_loss: 0.2082\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1972 - val_loss: 0.2084\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1970 - val_loss: 0.2092\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1965 - val_loss: 0.2084\n",
      "Epoch 51/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1968 - val_loss: 0.2087\n",
      "Epoch 52/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1972 - val_loss: 0.2089\n",
      "Epoch 53/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1965 - val_loss: 0.2087\n",
      "Epoch 54/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1967 - val_loss: 0.2090\n",
      "Epoch 55/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1968 - val_loss: 0.2085\n",
      "Epoch 56/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1961 - val_loss: 0.2085\n",
      "Epoch 57/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1964 - val_loss: 0.2086\n",
      "Epoch 58/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1963 - val_loss: 0.2088\n",
      "Epoch 59/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1967 - val_loss: 0.2084\n",
      "Epoch 60/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1955 - val_loss: 0.2086\n",
      "Epoch 61/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1962 - val_loss: 0.2088\n",
      "Epoch 62/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1966 - val_loss: 0.2085\n",
      "Epoch 63/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1966 - val_loss: 0.2085\n",
      "Epoch 64/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1962 - val_loss: 0.2085\n",
      "Epoch 65/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1965 - val_loss: 0.2086\n",
      "Epoch 66/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1963 - val_loss: 0.2085\n",
      "Epoch 67/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1958 - val_loss: 0.2086\n",
      "Fold 5 NN: 0.20818\n"
     ]
    }
   ],
   "source": [
    "# casio\n",
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "n_folds = 5\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2020)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = list(train)\n",
    "\n",
    "features_to_consider.remove('time_id')\n",
    "features_to_consider.remove('target')\n",
    "features_to_consider.remove('row_id')\n",
    "try:\n",
    "    features_to_consider.remove('pred_NN')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "train[features_to_consider] = train[features_to_consider].fillna(train[features_to_consider].mean())\n",
    "test[features_to_consider] = test[features_to_consider].fillna(train[features_to_consider].mean())\n",
    "\n",
    "train[pred_name] = 0\n",
    "test['target'] = 0\n",
    "\n",
    "\n",
    "for n_count in range(n_folds):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    indexes = np.arange(nfolds).astype(int)    \n",
    "    indexes = np.delete(indexes,obj=n_count, axis=0) \n",
    "    \n",
    "    indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n",
    "    \n",
    "    X_train = train.loc[train.time_id.isin(indexes), features_to_consider]\n",
    "    y_train = train.loc[train.time_id.isin(indexes), target_name]\n",
    "    X_test = train.loc[train.time_id.isin(values[n_count]), features_to_consider]\n",
    "    y_test = train.loc[train.time_id.isin(values[n_count]), target_name]\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    \n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.0053), #0.005\n",
    "        loss=root_mean_squared_per_error\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        features_to_consider.remove('stock_id')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_data = X_train[features_to_consider]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))         \n",
    "    num_data = scaler.fit_transform(num_data.values)    \n",
    "    \n",
    "    cat_data = X_train['stock_id']    \n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[features_to_consider]\n",
    "    num_data_test = scaler.transform(num_data_test.values)\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target,               \n",
    "              batch_size=2048,\n",
    "              epochs=200, # 1000\n",
    "              validation_data=([cat_data_test, num_data_test], y_test),\n",
    "              callbacks=[es, plateau],\n",
    "              validation_batch_size=len(y_test),\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    \n",
    "    tt =scaler.transform(test[features_to_consider].values)\n",
    "    test[target_name] += model.predict([test['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)\n",
    "    #test[target_name] += model.predict([test['stock_id'], test[features_to_consider]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "    counter += 1\n",
    "    features_to_consider.append('stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47a47a29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:38:18.679147Z",
     "iopub.status.busy": "2021-09-27T12:38:18.678226Z",
     "iopub.status.idle": "2021-09-27T12:38:18.681135Z",
     "shell.execute_reply": "2021-09-27T12:38:18.680644Z"
    },
    "papermill": {
     "duration": 3.378459,
     "end_time": "2021-09-27T12:38:18.681292",
     "exception": false,
     "start_time": "2021-09-27T12:38:15.302833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred1_nn=test['target'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "451ad9f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:38:25.425139Z",
     "iopub.status.busy": "2021-09-27T12:38:25.424159Z",
     "iopub.status.idle": "2021-09-27T12:53:58.402237Z",
     "shell.execute_reply": "2021-09-27T12:53:58.402983Z"
    },
    "papermill": {
     "duration": 936.318797,
     "end_time": "2021-09-27T12:53:58.403207",
     "exception": false,
     "start_time": "2021-09-27T12:38:22.084410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/5\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 39.2146 - val_loss: 5.5275\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 2.9821 - val_loss: 1.9761\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 1.2329 - val_loss: 0.8722\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.7904 - val_loss: 0.5874\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.6611 - val_loss: 0.2252\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.3105 - val_loss: 0.8806\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 1.5177 - val_loss: 0.3629\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2892 - val_loss: 0.2856\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.3004 - val_loss: 0.3104\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.3060 - val_loss: 0.3063\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.3206 - val_loss: 0.2598\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.3059 - val_loss: 0.2262\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2101 - val_loss: 0.2108\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2075 - val_loss: 0.2120\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2082 - val_loss: 0.2119\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2069 - val_loss: 0.2098\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2060 - val_loss: 0.2138\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2086 - val_loss: 0.2374\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2103 - val_loss: 0.2078\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2059 - val_loss: 0.2470\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2106 - val_loss: 0.2246\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2083 - val_loss: 0.2442\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2113 - val_loss: 0.2410\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2105 - val_loss: 0.2139\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2068 - val_loss: 0.2345\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2156 - val_loss: 0.2139\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2043 - val_loss: 0.2057\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2017 - val_loss: 0.2052\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2008 - val_loss: 0.2082\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2028 - val_loss: 0.2053\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2011 - val_loss: 0.2105\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2017 - val_loss: 0.2047\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2004 - val_loss: 0.2072\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2013 - val_loss: 0.2056\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2018 - val_loss: 0.2057\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2013 - val_loss: 0.2061\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2011 - val_loss: 0.2157\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2012 - val_loss: 0.2054\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2020 - val_loss: 0.2097\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1996 - val_loss: 0.2044\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1984 - val_loss: 0.2044\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1990 - val_loss: 0.2044\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1991 - val_loss: 0.2048\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1988 - val_loss: 0.2046\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1991 - val_loss: 0.2058\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1983 - val_loss: 0.2051\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1988 - val_loss: 0.2050\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1984 - val_loss: 0.2043\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1986 - val_loss: 0.2042\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1985 - val_loss: 0.2046\n",
      "Epoch 51/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1978 - val_loss: 0.2043\n",
      "Epoch 52/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1982 - val_loss: 0.2047\n",
      "Epoch 53/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1981 - val_loss: 0.2048\n",
      "Epoch 54/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1985 - val_loss: 0.2042\n",
      "Epoch 55/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1978 - val_loss: 0.2042\n",
      "Epoch 56/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1980 - val_loss: 0.2043\n",
      "Epoch 57/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1977 - val_loss: 0.2043\n",
      "Epoch 58/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1981 - val_loss: 0.2043\n",
      "Epoch 59/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1980 - val_loss: 0.2043\n",
      "Epoch 60/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1977 - val_loss: 0.2044\n",
      "Epoch 61/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1975 - val_loss: 0.2043\n",
      "Epoch 62/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1977 - val_loss: 0.2043\n",
      "Epoch 63/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1977 - val_loss: 0.2043\n",
      "Epoch 64/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1981 - val_loss: 0.2043\n",
      "Epoch 65/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1987 - val_loss: 0.2043\n",
      "Epoch 66/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1979 - val_loss: 0.2043\n",
      "Epoch 67/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1984 - val_loss: 0.2043\n",
      "Epoch 68/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1983 - val_loss: 0.2043\n",
      "Epoch 69/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1987 - val_loss: 0.2043\n",
      "Fold 1 NN: 0.20419\n",
      "CV 2/5\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 40.7106 - val_loss: 1.9709\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 2.8825 - val_loss: 2.1918\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 1.6673 - val_loss: 1.2223\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.9013 - val_loss: 0.7672\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.9164 - val_loss: 0.6762\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.8256 - val_loss: 0.9392\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.8077 - val_loss: 0.6985\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.7527 - val_loss: 0.7290\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.8154 - val_loss: 0.2584\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.4719 - val_loss: 0.7757\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.7088 - val_loss: 0.8442\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.6831 - val_loss: 0.4508\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.6939 - val_loss: 0.5613\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.5589 - val_loss: 0.3013\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.9039 - val_loss: 0.5977\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.4845 - val_loss: 0.4256\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2376 - val_loss: 0.2131\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2090 - val_loss: 0.2116\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2076 - val_loss: 0.2112\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2073 - val_loss: 0.2131\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2090 - val_loss: 0.2105\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2072 - val_loss: 0.2110\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2078 - val_loss: 0.2248\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2085 - val_loss: 0.2172\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2063 - val_loss: 0.2097\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2063 - val_loss: 0.2163\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2058 - val_loss: 0.2099\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2063 - val_loss: 0.2087\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2059 - val_loss: 0.2274\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2106 - val_loss: 0.2136\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2074 - val_loss: 0.2212\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2097 - val_loss: 0.2184\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2071 - val_loss: 0.2100\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2077 - val_loss: 0.2126\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2085 - val_loss: 0.2304\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2039 - val_loss: 0.2078\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2007 - val_loss: 0.2069\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2004 - val_loss: 0.2078\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1996 - val_loss: 0.2068\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2002 - val_loss: 0.2074\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2014 - val_loss: 0.2150\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2014 - val_loss: 0.2083\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2003 - val_loss: 0.2086\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2005 - val_loss: 0.2070\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1997 - val_loss: 0.2069\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1993 - val_loss: 0.2071\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1987 - val_loss: 0.2065\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1984 - val_loss: 0.2062\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1989 - val_loss: 0.2066\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1992 - val_loss: 0.2065\n",
      "Epoch 51/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1995 - val_loss: 0.2071\n",
      "Epoch 52/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1982 - val_loss: 0.2073\n",
      "Epoch 53/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1994 - val_loss: 0.2063\n",
      "Epoch 54/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1984 - val_loss: 0.2063\n",
      "Epoch 55/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1982 - val_loss: 0.2064\n",
      "Epoch 56/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1983 - val_loss: 0.2065\n",
      "Epoch 57/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1982 - val_loss: 0.2065\n",
      "Epoch 58/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1981 - val_loss: 0.2064\n",
      "Epoch 59/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1983 - val_loss: 0.2065\n",
      "Epoch 60/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1985 - val_loss: 0.2065\n",
      "Epoch 61/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1981 - val_loss: 0.2066\n",
      "Epoch 62/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1978 - val_loss: 0.2065\n",
      "Epoch 63/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1981 - val_loss: 0.2065\n",
      "Epoch 64/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1981 - val_loss: 0.2065\n",
      "Epoch 65/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1981 - val_loss: 0.2064\n",
      "Epoch 66/200\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.1975 - val_loss: 0.2065\n",
      "Epoch 67/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1978 - val_loss: 0.2065\n",
      "Epoch 68/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1977 - val_loss: 0.2064\n",
      "Fold 2 NN: 0.20615\n",
      "CV 3/5\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 33.5777 - val_loss: 1.7638\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.4303 - val_loss: 0.7512\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.7029 - val_loss: 0.7650\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.6467 - val_loss: 0.9805\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.6557 - val_loss: 0.5982\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.8639 - val_loss: 0.5273\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.5679 - val_loss: 0.7179\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.6278 - val_loss: 0.6952\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.6714 - val_loss: 0.2640\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.4929 - val_loss: 0.4866\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.1673 - val_loss: 0.2388\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2346 - val_loss: 0.2299\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2463 - val_loss: 0.2213\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2533 - val_loss: 0.2883\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2620 - val_loss: 0.2282\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2612 - val_loss: 0.2675\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2664 - val_loss: 0.2277\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2694 - val_loss: 0.3931\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2674 - val_loss: 0.2133\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2651 - val_loss: 0.2518\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2737 - val_loss: 0.2195\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.2644 - val_loss: 0.2705\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2714 - val_loss: 0.2473\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.4481 - val_loss: 0.2549\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2352 - val_loss: 0.2767\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2409 - val_loss: 0.3761\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2236 - val_loss: 0.2058\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2015 - val_loss: 0.2052\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2016 - val_loss: 0.2054\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2012 - val_loss: 0.2158\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2016 - val_loss: 0.2135\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2017 - val_loss: 0.2077\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2014 - val_loss: 0.2066\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2014 - val_loss: 0.2082\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2013 - val_loss: 0.2113\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1994 - val_loss: 0.2046\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1985 - val_loss: 0.2051\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1980 - val_loss: 0.2060\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1985 - val_loss: 0.2050\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1987 - val_loss: 0.2055\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1980 - val_loss: 0.2058\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1987 - val_loss: 0.2050\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1987 - val_loss: 0.2071\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1979 - val_loss: 0.2049\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1980 - val_loss: 0.2049\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1976 - val_loss: 0.2048\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1969 - val_loss: 0.2049\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1974 - val_loss: 0.2050\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.1977 - val_loss: 0.2054\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1978 - val_loss: 0.2050\n",
      "Epoch 51/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1970 - val_loss: 0.2049\n",
      "Epoch 52/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1972 - val_loss: 0.2049\n",
      "Epoch 53/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1977 - val_loss: 0.2049\n",
      "Epoch 54/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1973 - val_loss: 0.2051\n",
      "Epoch 55/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1966 - val_loss: 0.2050\n",
      "Epoch 56/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1973 - val_loss: 0.2051\n",
      "Fold 3 NN: 0.20455\n",
      "CV 4/5\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 40.5631 - val_loss: 2.1031\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 1.4305 - val_loss: 1.1779\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.9754 - val_loss: 0.8558\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.8957 - val_loss: 0.5916\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.8165 - val_loss: 0.8735\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.7665 - val_loss: 0.4423\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.6208 - val_loss: 0.6572\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.5383 - val_loss: 0.4551\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.4981 - val_loss: 0.3996\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.8570 - val_loss: 0.2332\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2315 - val_loss: 0.2644\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2492 - val_loss: 0.2860\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2496 - val_loss: 0.2303\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2671 - val_loss: 0.2166\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.3316 - val_loss: 0.2963\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2506 - val_loss: 0.2254\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.2284 - val_loss: 0.2511\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.2318 - val_loss: 0.2418\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2492 - val_loss: 0.2365\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2407 - val_loss: 0.2414\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2534 - val_loss: 0.2658\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2106 - val_loss: 0.2099\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2038 - val_loss: 0.2096\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2034 - val_loss: 0.2102\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2029 - val_loss: 0.2101\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2030 - val_loss: 0.2104\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2033 - val_loss: 0.2136\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2034 - val_loss: 0.2153\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2045 - val_loss: 0.2268\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2044 - val_loss: 0.2132\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2014 - val_loss: 0.2104\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2012 - val_loss: 0.2093\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2006 - val_loss: 0.2091\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2009 - val_loss: 0.2102\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2001 - val_loss: 0.2095\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2012 - val_loss: 0.2092\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2002 - val_loss: 0.2088\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2001 - val_loss: 0.2090\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2007 - val_loss: 0.2084\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2004 - val_loss: 0.2089\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1999 - val_loss: 0.2096\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2001 - val_loss: 0.2088\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2001 - val_loss: 0.2139\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.2016 - val_loss: 0.2111\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2006 - val_loss: 0.2164\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2013 - val_loss: 0.2103\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1996 - val_loss: 0.2083\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1986 - val_loss: 0.2086\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1988 - val_loss: 0.2084\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1989 - val_loss: 0.2083\n",
      "Epoch 51/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1990 - val_loss: 0.2088\n",
      "Epoch 52/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1988 - val_loss: 0.2085\n",
      "Epoch 53/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1983 - val_loss: 0.2087\n",
      "Epoch 54/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1991 - val_loss: 0.2084\n",
      "Epoch 55/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1986 - val_loss: 0.2090\n",
      "Epoch 56/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1990 - val_loss: 0.2091\n",
      "Epoch 57/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1990 - val_loss: 0.2093\n",
      "Epoch 58/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1984 - val_loss: 0.2082\n",
      "Epoch 59/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1984 - val_loss: 0.2084\n",
      "Epoch 60/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1980 - val_loss: 0.2083\n",
      "Epoch 61/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1980 - val_loss: 0.2083\n",
      "Epoch 62/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1985 - val_loss: 0.2081\n",
      "Epoch 63/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1980 - val_loss: 0.2083\n",
      "Epoch 64/200\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1991 - val_loss: 0.2083\n",
      "Epoch 65/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1987 - val_loss: 0.2082\n",
      "Epoch 66/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1973 - val_loss: 0.2082\n",
      "Epoch 67/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1979 - val_loss: 0.2082\n",
      "Epoch 68/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1978 - val_loss: 0.2082\n",
      "Epoch 69/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1975 - val_loss: 0.2082\n",
      "Epoch 70/200\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.1985 - val_loss: 0.2081\n",
      "Epoch 71/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1979 - val_loss: 0.2082\n",
      "Epoch 72/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1980 - val_loss: 0.2081\n",
      "Epoch 73/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1977 - val_loss: 0.2081\n",
      "Epoch 74/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1979 - val_loss: 0.2082\n",
      "Epoch 75/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1979 - val_loss: 0.2082\n",
      "Epoch 76/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1980 - val_loss: 0.2082\n",
      "Epoch 77/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1977 - val_loss: 0.2082\n",
      "Epoch 78/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1977 - val_loss: 0.2082\n",
      "Epoch 79/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1982 - val_loss: 0.2082\n",
      "Epoch 80/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1982 - val_loss: 0.2082\n",
      "Epoch 81/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.1977 - val_loss: 0.2082\n",
      "Epoch 82/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1977 - val_loss: 0.2082\n",
      "Fold 4 NN: 0.20814\n",
      "CV 5/5\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 40.9257 - val_loss: 2.5191\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 2.1881 - val_loss: 2.9017\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.7891 - val_loss: 1.2721\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 1.4138 - val_loss: 1.0436\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.2504 - val_loss: 1.1984\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.2216 - val_loss: 1.2077\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 1.2071 - val_loss: 2.8842\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.4428 - val_loss: 1.2020\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.1509 - val_loss: 1.2122\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 1.1610 - val_loss: 1.6049\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 1.1565 - val_loss: 0.7149\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 1.0833 - val_loss: 2.2820\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 1.4717 - val_loss: 1.2091\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 1.2570 - val_loss: 1.2691\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 1.2135 - val_loss: 0.5946\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 1.1543 - val_loss: 1.0776\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 1.1968 - val_loss: 0.9640\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.1788 - val_loss: 1.2059\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 1.2756 - val_loss: 1.7891\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.1707 - val_loss: 1.4452\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 1.1849 - val_loss: 1.0952\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 1.1647 - val_loss: 1.2652\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.3846 - val_loss: 0.2183\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2108 - val_loss: 0.2512\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2132 - val_loss: 0.2161\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2097 - val_loss: 0.2286\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2112 - val_loss: 0.2203\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2102 - val_loss: 0.2310\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2128 - val_loss: 0.2576\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2194 - val_loss: 0.2550\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2250 - val_loss: 0.2136\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2213 - val_loss: 0.2600\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2289 - val_loss: 0.2787\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2272 - val_loss: 0.3328\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.2330 - val_loss: 0.2154\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2306 - val_loss: 0.2212\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2326 - val_loss: 0.3127\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.2325 - val_loss: 0.2279\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2025 - val_loss: 0.2096\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1999 - val_loss: 0.2121\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.2006 - val_loss: 0.2094\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1995 - val_loss: 0.2100\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1992 - val_loss: 0.2179\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2005 - val_loss: 0.2177\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1998 - val_loss: 0.2170\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1993 - val_loss: 0.2157\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2008 - val_loss: 0.2450\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2046 - val_loss: 0.2165\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1986 - val_loss: 0.2101\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1973 - val_loss: 0.2092\n",
      "Epoch 51/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1977 - val_loss: 0.2094\n",
      "Epoch 52/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1980 - val_loss: 0.2099\n",
      "Epoch 53/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1974 - val_loss: 0.2093\n",
      "Epoch 54/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1976 - val_loss: 0.2117\n",
      "Epoch 55/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1978 - val_loss: 0.2096\n",
      "Epoch 56/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1974 - val_loss: 0.2092\n",
      "Epoch 57/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1974 - val_loss: 0.2125\n",
      "Epoch 58/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1972 - val_loss: 0.2094\n",
      "Epoch 59/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1973 - val_loss: 0.2092\n",
      "Epoch 60/200\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1962 - val_loss: 0.2095\n",
      "Epoch 61/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1970 - val_loss: 0.2099\n",
      "Epoch 62/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1974 - val_loss: 0.2095\n",
      "Epoch 63/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1973 - val_loss: 0.2097\n",
      "Epoch 64/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1968 - val_loss: 0.2094\n",
      "Epoch 65/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1974 - val_loss: 0.2094\n",
      "Epoch 66/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1970 - val_loss: 0.2094\n",
      "Epoch 67/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1964 - val_loss: 0.2095\n",
      "Epoch 68/200\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1970 - val_loss: 0.2095\n",
      "Epoch 69/200\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1974 - val_loss: 0.2094\n",
      "Epoch 70/200\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1971 - val_loss: 0.2095\n",
      "Fold 5 NN: 0.20916\n"
     ]
    }
   ],
   "source": [
    "# citizen\n",
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "n_folds = 5\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=29)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = list(train)\n",
    "\n",
    "features_to_consider.remove('time_id')\n",
    "features_to_consider.remove('target')\n",
    "features_to_consider.remove('row_id')\n",
    "try:\n",
    "    features_to_consider.remove('pred_NN')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "train[features_to_consider] = train[features_to_consider].fillna(train[features_to_consider].mean())\n",
    "test[features_to_consider] = test[features_to_consider].fillna(train[features_to_consider].mean())\n",
    "\n",
    "train[pred_name] = 0\n",
    "test['target'] = 0\n",
    "\n",
    "\n",
    "for n_count in range(n_folds):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    indexes = np.arange(nfolds).astype(int)    \n",
    "    indexes = np.delete(indexes,obj=n_count, axis=0) \n",
    "    \n",
    "    indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n",
    "    \n",
    "    X_train = train.loc[train.time_id.isin(indexes), features_to_consider]\n",
    "    y_train = train.loc[train.time_id.isin(indexes), target_name]\n",
    "    X_test = train.loc[train.time_id.isin(values[n_count]), features_to_consider]\n",
    "    y_test = train.loc[train.time_id.isin(values[n_count]), target_name]\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    \n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.0065), #0.005\n",
    "        loss=root_mean_squared_per_error\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        features_to_consider.remove('stock_id')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_data = X_train[features_to_consider]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))         \n",
    "    num_data = scaler.fit_transform(num_data.values)    \n",
    "    \n",
    "    cat_data = X_train['stock_id']    \n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[features_to_consider]\n",
    "    num_data_test = scaler.transform(num_data_test.values)\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target,               \n",
    "              batch_size=2048,\n",
    "              epochs=200, # 1000\n",
    "              validation_data=([cat_data_test, num_data_test], y_test),\n",
    "              callbacks=[es, plateau],\n",
    "              validation_batch_size=len(y_test),\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    \n",
    "    tt =scaler.transform(test[features_to_consider].values)\n",
    "    test[target_name] += model.predict([test['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)\n",
    "    #test[target_name] += model.predict([test['stock_id'], test[features_to_consider]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "    counter += 1\n",
    "    features_to_consider.append('stock_id')\n",
    "pred2_nn=test['target'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5ec6aa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:54:12.130560Z",
     "iopub.status.busy": "2021-09-27T12:54:12.129594Z",
     "iopub.status.idle": "2021-09-27T12:54:12.135930Z",
     "shell.execute_reply": "2021-09-27T12:54:12.135462Z"
    },
    "papermill": {
     "duration": 6.8387,
     "end_time": "2021-09-27T12:54:12.136092",
     "exception": false,
     "start_time": "2021-09-27T12:54:05.297392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # rolex\n",
    "# model_name = 'NN'\n",
    "# pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "# n_folds = 4\n",
    "# kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=29)\n",
    "# scores_folds[model_name] = []\n",
    "# counter = 1\n",
    "\n",
    "# features_to_consider = list(train)\n",
    "\n",
    "# features_to_consider.remove('time_id')\n",
    "# features_to_consider.remove('target')\n",
    "# features_to_consider.remove('row_id')\n",
    "# try:\n",
    "#     features_to_consider.remove('pred_NN')\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "\n",
    "# train[features_to_consider] = train[features_to_consider].fillna(train[features_to_consider].mean())\n",
    "# test[features_to_consider] = test[features_to_consider].fillna(train[features_to_consider].mean())\n",
    "\n",
    "# train[pred_name] = 0\n",
    "# test['target'] = 0\n",
    "\n",
    "\n",
    "# for n_count in range(n_folds):\n",
    "#     print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "#     indexes = np.arange(nfolds).astype(int)    \n",
    "#     indexes = np.delete(indexes,obj=n_count, axis=0) \n",
    "    \n",
    "#     indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n",
    "    \n",
    "#     X_train = train.loc[train.time_id.isin(indexes), features_to_consider]\n",
    "#     y_train = train.loc[train.time_id.isin(indexes), target_name]\n",
    "#     X_test = train.loc[train.time_id.isin(values[n_count]), features_to_consider]\n",
    "#     y_test = train.loc[train.time_id.isin(values[n_count]), target_name]\n",
    "    \n",
    "#     #############################################################################################\n",
    "#     # NN\n",
    "#     #############################################################################################\n",
    "    \n",
    "#     model = base_model()\n",
    "    \n",
    "#     model.compile(\n",
    "#         keras.optimizers.Adam(learning_rate=0.001), #0.005\n",
    "#         loss=root_mean_squared_per_error\n",
    "#     )\n",
    "    \n",
    "#     try:\n",
    "#         features_to_consider.remove('stock_id')\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     num_data = X_train[features_to_consider]\n",
    "    \n",
    "#     scaler = MinMaxScaler(feature_range=(-1, 1))         \n",
    "#     num_data = scaler.fit_transform(num_data.values)    \n",
    "    \n",
    "#     cat_data = X_train['stock_id']    \n",
    "#     target =  y_train\n",
    "    \n",
    "#     num_data_test = X_test[features_to_consider]\n",
    "#     num_data_test = scaler.transform(num_data_test.values)\n",
    "#     cat_data_test = X_test['stock_id']\n",
    "\n",
    "#     model.fit([cat_data, num_data], \n",
    "#               target,               \n",
    "#               batch_size=2048,\n",
    "#               epochs=200, # 1000\n",
    "#               validation_data=([cat_data_test, num_data_test], y_test),\n",
    "#               callbacks=[es, plateau],\n",
    "#               validation_batch_size=len(y_test),\n",
    "#               shuffle=True,\n",
    "#              verbose = 1)\n",
    "\n",
    "#     preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "#     score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "#     print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "#     scores_folds[model_name].append(score)\n",
    "    \n",
    "#     tt =scaler.transform(test[features_to_consider].values)\n",
    "#     test[target_name] += model.predict([test['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)\n",
    "#     #test[target_name] += model.predict([test['stock_id'], test[features_to_consider]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "#     counter += 1\n",
    "#     features_to_consider.append('stock_id')\n",
    "# pred3_nn=test['target'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "018af062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:54:25.704812Z",
     "iopub.status.busy": "2021-09-27T12:54:25.704207Z",
     "iopub.status.idle": "2021-09-27T12:54:25.706475Z",
     "shell.execute_reply": "2021-09-27T12:54:25.705865Z"
    },
    "papermill": {
     "duration": 6.832668,
     "end_time": "2021-09-27T12:54:25.706617",
     "exception": false,
     "start_time": "2021-09-27T12:54:18.873949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test['target'] = predictions_lgb*0.5 + predictions_lgb2*0.5\n",
    "# preds_lgb = predictions_lgb*0.5 + predictions_lgb2*0.5\n",
    "# test[['row_id', 'target']].to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5bd259e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:54:39.311209Z",
     "iopub.status.busy": "2021-09-27T12:54:39.310519Z",
     "iopub.status.idle": "2021-09-27T12:54:39.314178Z",
     "shell.execute_reply": "2021-09-27T12:54:39.313570Z"
    },
    "papermill": {
     "duration": 6.780075,
     "end_time": "2021-09-27T12:54:39.314319",
     "exception": false,
     "start_time": "2021-09-27T12:54:32.534244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictions_lgb0= train_and_evaluate_lgb(train, test,params0)\n",
    "# predictions_lgb1= train_and_evaluate_lgb(train, test,params1, boost=10000)\n",
    "# predictions_lgb2= train_and_evaluate_lgb(train, test,params2, boost=10000)\n",
    "# predictions_lgb3= train_and_evaluate_lgb(train, test,params3, boost=10000)\n",
    "# predictions_lgb4= train_and_evaluate_lgb(train, test,params4, boost=10000)\n",
    "# pred3_nn=pred3_nn/4\n",
    "pred2_nn=pred2_nn/5\n",
    "pred1_nn=pred1_nn/5\n",
    "# preds_nn = (pred2_nn*0.4+pred1_nn*0.4+pred3_nn*0.2)\n",
    "# preds_nn\n",
    "# test['target'] = preds_lgb*0.4 + preds_nn*0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2895ae44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T12:54:53.044816Z",
     "iopub.status.busy": "2021-09-27T12:54:53.044193Z",
     "iopub.status.idle": "2021-09-27T12:54:53.051414Z",
     "shell.execute_reply": "2021-09-27T12:54:53.050713Z"
    },
    "papermill": {
     "duration": 6.851143,
     "end_time": "2021-09-27T12:54:53.051572",
     "exception": false,
     "start_time": "2021-09-27T12:54:46.200429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# test['target'] = pred2_nn*0.3 + pred1_nn*0.3 +\\\n",
    "# #                  pred3_nn*0.1 +\\\n",
    "#                  predictions_lgb0*0.05 + \\\n",
    "#                  predictions_lgb1*0.25 + predictions_lgb2*0.05\n",
    "# + predictions_lgb3*0.05 + predictions_lgb4*0.05\n",
    "test['target'] = pred2_nn*0.3 + pred1_nn*0.3 + predictions_lgb0*0.05 + predictions_lgb1*0.3 + predictions_lgb2*0.05 \n",
    "# test['target'] = preds_nn\n",
    "test[['row_id', 'target']].to_csv('submission.csv',index = False)\n",
    "# test[['row_id', 'target']]\n",
    "# test[['row_id', 'target']].to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb685e8",
   "metadata": {
    "papermill": {
     "duration": 6.859864,
     "end_time": "2021-09-27T12:55:06.686830",
     "exception": false,
     "start_time": "2021-09-27T12:54:59.826966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b74191",
   "metadata": {
    "papermill": {
     "duration": 6.827744,
     "end_time": "2021-09-27T12:55:20.246923",
     "exception": false,
     "start_time": "2021-09-27T12:55:13.419179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8cfaaa",
   "metadata": {
    "papermill": {
     "duration": 6.811852,
     "end_time": "2021-09-27T12:55:33.911800",
     "exception": false,
     "start_time": "2021-09-27T12:55:27.099948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73324e91",
   "metadata": {
    "papermill": {
     "duration": 6.878358,
     "end_time": "2021-09-27T12:55:47.537863",
     "exception": false,
     "start_time": "2021-09-27T12:55:40.659505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11999.695494,
   "end_time": "2021-09-27T12:55:56.718093",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-27T09:35:57.022599",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
